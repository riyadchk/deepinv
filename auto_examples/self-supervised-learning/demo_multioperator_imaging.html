<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Self-supervised learning from incomplete measurements of multiple operators. &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <link rel="shortcut icon" href="../../_static/logo.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script>window.MathJax = {"tex": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}, "macros": {"forw": ["{A\\left({#1}\\right)}", 1], "noise": ["{N\\left({#1}\\right)}", 1], "inverse": ["{R\\left({#1}\\right)}", 1], "inversef": ["{R\\left({#1},{#2}\\right)}", 2], "reg": ["{g\\left({#1}\\right)}", 1], "regname": "g", "sensor": ["{\\eta\\left({#1}\\right)}", 1], "datafid": ["{f\\left({#1},{#2}\\right)}", 2], "datafidname": "f", "distance": ["{d\\left({#1},{#2}\\right)}", 2], "distancename": "d", "denoiser": ["{\\operatorname{D}_{{#2}}\\left({#1}\\right)}", 2], "denoisername": "\\operatorname{D}", "xset": "\\mathcal{X}", "yset": "\\mathcal{Y}", "group": "\\mathcal{G}", "metric": ["{d\\left({#1},{#2}\\right)}", 2], "loss": ["{\\mathcal\\left({#1}\\right)}", 1]}}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Self-supervised learning with Equivariant Imaging for MRI." href="demo_equivariant_imaging.html" />
    <link rel="prev" title="Self-supervised denoising with the Neighbor2Neighbor loss." href="demo_n2n_denoising.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.physics.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.pnp.html">PnP and RED algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.unfolded.html">Unfolded algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.sampling.html">Diffusion algorithms</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#basics">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#plug-and-play">Plug-and-Play</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#sampling">Sampling</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#self-supervised-learning">Self-Supervised Learning</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="demo_sure_denoising.html">Self-supervised denoising with the SURE loss.</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_n2n_denoising.html">Self-supervised denoising with the Neighbor2Neighbor loss.</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Self-supervised learning from incomplete measurements of multiple operators.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setup-paths-for-data-loading-and-results">Setup paths for data loading and results.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-base-image-datasets-and-degradation-operators">Load base image datasets and degradation operators.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generate-a-dataset-of-subsampled-images-and-load-it">Generate a dataset of subsampled images and load it.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-up-the-reconstruction-network">Set up the reconstruction network</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-up-the-training-parameters">Set up the training parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#train-the-network">Train the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="#test-the-network">Test the network</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="demo_equivariant_imaging.html">Self-supervised learning with Equivariant Imaging for MRI.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#unfolded">Unfolded</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.multigpu.html">Using multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Examples</a></li>
      <li class="breadcrumb-item active">Self-supervised learning from incomplete measurements of multiple operators.</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/auto_examples/self-supervised-learning/demo_multioperator_imaging.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-self-supervised-learning-demo-multioperator-imaging-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="self-supervised-learning-from-incomplete-measurements-of-multiple-operators">
<span id="sphx-glr-auto-examples-self-supervised-learning-demo-multioperator-imaging-py"></span><h1>Self-supervised learning from incomplete measurements of multiple operators.<a class="headerlink" href="#self-supervised-learning-from-incomplete-measurements-of-multiple-operators" title="Link to this heading"></a></h1>
<p>This example shows you how to train a reconstruction network for an inpainting
inverse problem on a fully self-supervised way, i.e., using measurement data only.</p>
<p>The dataset consists of pairs <span class="math notranslate nohighlight">\((y_i,A_{g_i})\)</span> where <span class="math notranslate nohighlight">\(y_i\)</span> are the measurements and <span class="math notranslate nohighlight">\(A_{g_i}\)</span> is a
binary sampling operator out of <span class="math notranslate nohighlight">\(G\)</span> (i.e., <span class="math notranslate nohighlight">\(g_i\in \{1,\dots,G\}\)</span>).</p>
<p>This self-supervised learning approach is presented in <a class="reference external" href="https://openreview.net/pdf?id=aV9WSvM6N3">“Unsupervised Learning From Incomplete Measurements for
Inverse Problems”</a>, and minimizes the loss function:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\theta) = \sum_{i=1}^{N} \left\|A_{g_i} \hat{x}_{i,\theta} - y_i \right\|_2^2 + \sum_{s=1}^{G}
\left\|\hat{x}_{i,\theta} - R_{\theta}(A_s\hat{x}_{i,\theta},A_s) \right\|_2^2\]</div>
<p>where <span class="math notranslate nohighlight">\(R_{\theta}\)</span> is a reconstruction network with parameters <span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(y_i\)</span> are the measurements,
<span class="math notranslate nohighlight">\(A_s\)</span> is a binary sampling operator, and <span class="math notranslate nohighlight">\(\hat{x}_{i,\theta} = R_{\theta}(y_i,A_{g_i})\)</span>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">deepinv</span> <span class="k">as</span> <span class="nn">dinv</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">deepinv.models.utils</span> <span class="kn">import</span> <span class="n">get_weights_url</span>
<span class="kn">from</span> <span class="nn">deepinv.training_utils</span> <span class="kn">import</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
</pre></div>
</div>
<section id="setup-paths-for-data-loading-and-results">
<h2>Setup paths for data loading and results.<a class="headerlink" href="#setup-paths-for-data-loading-and-results" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ORIGINAL_DATA_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;datasets&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DATA_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;measurements&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">RESULTS_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;results&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DEG_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;degradations&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CKPT_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;ckpts&quot;</span>

<span class="c1"># Set the global random seed from pytorch to ensure reproducibility of the example.</span>
<a href="https://pytorch.org/docs/2.0/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_freer_gpu</span><span class="p">()</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
</pre></div>
</div>
</section>
<section id="load-base-image-datasets-and-degradation-operators">
<h2>Load base image datasets and degradation operators.<a class="headerlink" href="#load-base-image-datasets-and-degradation-operators" title="Link to this heading"></a></h2>
<p>In this example, we use the MNIST dataset for training and testing.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>

<span class="n">train_base_dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span></a><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;../datasets/&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">test_base_dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span></a><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;../datasets/&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="generate-a-dataset-of-subsampled-images-and-load-it">
<h2>Generate a dataset of subsampled images and load it.<a class="headerlink" href="#generate-a-dataset-of-subsampled-images-and-load-it" title="Link to this heading"></a></h2>
<p>We generate 10 different inpainting operators, each one with a different random mask.
If the <a class="reference internal" href="../../stubs/deepinv.datasets.generate_dataset.html#deepinv.datasets.generate_dataset" title="deepinv.datasets.generate_dataset"><code class="xref py py-func docutils literal notranslate"><span class="pre">deepinv.datasets.generate_dataset()</span></code></a> receives a list of physics operators, it
generates a dataset for each operator and returns a list of paths to the generated datasets.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We only use 10 training images per operator to reduce the computational time of this example. You can use the whole
dataset by setting <code class="docutils literal notranslate"><span class="pre">n_images_max</span> <span class="pre">=</span> <span class="pre">None</span></code>.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">number_of_operators</span></a> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># defined physics</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">physics</span></a> <span class="o">=</span> <span class="p">[</span>
    <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">physics</span><span class="o">.</span><span class="n">Inpainting</span></a><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tensor_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">number_of_operators</span></a><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># Use parallel dataloader if using a GPU to reduce training time,</span>
<span class="c1"># otherwise, as all computes are on CPU, use synchronous data loading.</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a> <span class="o">=</span> <span class="mi">4</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_images_max</span></a> <span class="o">=</span> <span class="p">(</span>
    <span class="kc">None</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">50</span>
<span class="p">)</span>  <span class="c1"># number of images used for training (uses the whole dataset if you have a gpu)</span>

<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a> <span class="o">=</span> <span class="s2">&quot;inpainting&quot;</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">my_dataset_name</span></a> <span class="o">=</span> <span class="s2">&quot;demo_multioperator_imaging&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">measurement_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DATA_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;MNIST&quot;</span> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">deepinv_datasets_path</span></a> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">generate_dataset</span><span class="p">(</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset</span></a><span class="o">=</span><span class="n">train_base_dataset</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataset</span></a><span class="o">=</span><span class="n">test_base_dataset</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">physics</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">physics</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <span class="n">save_dir</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">measurement_dir</span></a><span class="p">,</span>
    <span class="n">train_datapoints</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_images_max</span></a><span class="p">,</span>
    <span class="n">test_datapoints</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span>
    <span class="n">dataset_filename</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">my_dataset_name</span></a><span class="p">),</span>
<span class="p">)</span>

<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset</span></a> <span class="o">=</span> <span class="p">[</span>
    <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">HDF5Dataset</span></a><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">deepinv_datasets_path</span></a>
<span class="p">]</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataset</span></a> <span class="o">=</span> <span class="p">[</span>
    <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">HDF5Dataset</span></a><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">deepinv_datasets_path</span></a>
<span class="p">]</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing train measurement vectors from base dataset of operator 1 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 419.72it/s]
Computing test measurement vectors from base dataset of operator 1 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 985.27it/s]
Computing train measurement vectors from base dataset of operator 2 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 531.87it/s]
Computing test measurement vectors from base dataset of operator 2 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 1021.75it/s]
Computing train measurement vectors from base dataset of operator 3 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 533.36it/s]
Computing test measurement vectors from base dataset of operator 3 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 1012.87it/s]
Computing train measurement vectors from base dataset of operator 4 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 540.36it/s]
Computing test measurement vectors from base dataset of operator 4 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 989.69it/s]
Computing train measurement vectors from base dataset of operator 5 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 542.74it/s]
Computing test measurement vectors from base dataset of operator 5 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 996.75it/s]
Computing train measurement vectors from base dataset of operator 6 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 534.78it/s]
Computing test measurement vectors from base dataset of operator 6 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 1011.16it/s]
Computing train measurement vectors from base dataset of operator 7 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 518.65it/s]
Computing test measurement vectors from base dataset of operator 7 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 1009.46it/s]
Computing train measurement vectors from base dataset of operator 8 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 534.44it/s]
Computing test measurement vectors from base dataset of operator 8 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 1027.76it/s]
Computing train measurement vectors from base dataset of operator 9 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 525.93it/s]
Computing test measurement vectors from base dataset of operator 9 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 1023.75it/s]
Computing train measurement vectors from base dataset of operator 10 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 529.45it/s]
Computing test measurement vectors from base dataset of operator 10 out of 10...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 1016.31it/s]
Dataset has been saved in measurements/MNIST/inpainting
</pre></div>
</div>
</section>
<section id="set-up-the-reconstruction-network">
<h2>Set up the reconstruction network<a class="headerlink" href="#set-up-the-reconstruction-network" title="Link to this heading"></a></h2>
<p>As a reconstruction network, we use a simple artifact removal network based on a U-Net.
The network is defined as a <span class="math notranslate nohighlight">\(R_{\theta}(y,A)=\phi_{\theta}(A^{\top}y)\)</span> where <span class="math notranslate nohighlight">\(\phi\)</span> is the U-Net.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the unfolded trainable model.</span>
<span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ArtifactRemoval</span></a><span class="p">(</span>
    <span class="n">backbone_net</span><span class="o">=</span><a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">UNet</span></a><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="set-up-the-training-parameters">
<h2>Set up the training parameters<a class="headerlink" href="#set-up-the-training-parameters" title="Link to this heading"></a></h2>
<p>We choose a self-supervised training scheme with two losses: the measurement consistency loss (MC)
and the multi-operator imaging loss (MOI).
Necessary and sufficient conditions on the number of operators and measurements are described
<a class="reference external" href="https://www.jmlr.org/papers/v24/22-0315.html">here</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We use a pretrained model to reduce training time. You can get the same results by training from scratch
for 100 epochs.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a> <span class="o">=</span> <span class="mi">1</span>
<a href="https://docs.python.org/3.4/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learning_rate</span></a> <span class="o">=</span> <span class="mf">5e-4</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a> <span class="o">=</span> <span class="mi">64</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">1</span>

<span class="c1"># choose self-supervised training losses</span>
<span class="c1"># generates 4 random rotations per image in the batch</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MCLoss</span></a><span class="p">(),</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">MOILoss</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">physics</span></a><span class="p">)]</span>

<span class="c1"># choose optimizer and scheduler</span>
<a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learning_rate</span></a><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>
<a href="https://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scheduler</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span></a><span class="p">(</span><a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># start with a pretrained model to reduce training time</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a> <span class="o">=</span> <span class="s2">&quot;demo_moi_ckp_10.pth&quot;</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">url</span></a> <span class="o">=</span> <span class="n">get_weights_url</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;demo&quot;</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a><span class="p">)</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/hub.html#torch.hub.load_state_dict_from_url" title="torch.hub.load_state_dict_from_url" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span></a><span class="p">(</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">url</span></a><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">file_name</span></a>
<span class="p">)</span>
<span class="c1"># load a checkpoint to reduce training time</span>
<a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">])</span>
<a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam.load_state_dict" title="torch.optim.Adam.load_state_dict" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ckpt</span></a><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://huggingface.co/deepinv/demo/resolve/main/demo_moi_ckp_10.pth?download=true&quot; to /home/runner/.cache/torch/hub/checkpoints/demo_moi_ckp_10.pth

  0%|          | 0.00/23.8M [00:00&lt;?, ?B/s]
 80%|████████  | 19.1M/23.8M [00:00&lt;00:00, 200MB/s]
100%|██████████| 23.8M/23.8M [00:00&lt;00:00, 215MB/s]
</pre></div>
</div>
</section>
<section id="train-the-network">
<h2>Train the network<a class="headerlink" href="#train-the-network" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># print training information</span>
<a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># plot curves and images in Weight&amp;Bias</span>

<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a> <span class="o">=</span> <span class="p">[</span>
    <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset</span></a>
<span class="p">]</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a> <span class="o">=</span> <span class="p">[</span>
    <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_size</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataset</span></a>
<span class="p">]</span>

<span class="n">train</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="p">,</span>
    <span class="n">eval_dataloader</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">,</span>
    <a href="https://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scheduler</span></a><span class="o">=</span><a href="https://pytorch.org/docs/2.0/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" title="torch.optim.lr_scheduler.StepLR" class="sphx-glr-backref-module-torch-optim-lr_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">scheduler</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">physics</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">physics</span></a><span class="p">,</span>
    <a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a><span class="o">=</span><a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <span class="n">save_path</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CKPT_DIR</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a><span class="p">),</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="p">,</span>
    <span class="n">ckp_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The model has 2069441 trainable parameters

  0%|          | 0/5 [00:00&lt;?, ?it/s]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.00131, loss_moi=0.000454, total_loss=0.00177, train_psnr=20]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.000946, loss_moi=0.00427, total_loss=0.00522, train_psnr=20.9]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.00169, loss_moi=0.00734, total_loss=0.00903, train_psnr=19.3]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.0029, loss_moi=0.00811, total_loss=0.011, train_psnr=19]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.00475, loss_moi=0.00865, total_loss=0.0134, train_psnr=18.2]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.00557, loss_moi=0.00878, total_loss=0.0143, train_psnr=17.8]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.00631, loss_moi=0.00939, total_loss=0.0157, train_psnr=17.4]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.00659, loss_moi=0.00987, total_loss=0.0165, train_psnr=17.1]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.00657, loss_moi=0.00961, total_loss=0.0162, train_psnr=17]
Epoch 1:   0%|          | 0/5 [00:00&lt;?, ?it/s, eval_psnr=23.5, loss_mc=0.00642, loss_moi=0.00891, total_loss=0.0153, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00642, loss_moi=0.00891, total_loss=0.0153, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00642, loss_moi=0.00891, total_loss=0.0153, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00593, loss_moi=0.00891, total_loss=0.0148, train_psnr=16.7]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00565, loss_moi=0.00912, total_loss=0.0148, train_psnr=16.7]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00537, loss_moi=0.00886, total_loss=0.0142, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00527, loss_moi=0.00864, total_loss=0.0139, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00507, loss_moi=0.0086, total_loss=0.0137, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00487, loss_moi=0.00872, total_loss=0.0136, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.0048, loss_moi=0.00865, total_loss=0.0134, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00474, loss_moi=0.00861, total_loss=0.0134, train_psnr=16.9]
Epoch 1:  20%|██        | 1/5 [00:00&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00465, loss_moi=0.00836, total_loss=0.013, train_psnr=17]
Epoch 1:  20%|██        | 1/5 [00:01&lt;00:02,  1.91it/s, eval_psnr=23.5, loss_mc=0.00456, loss_moi=0.00813, total_loss=0.0127, train_psnr=17]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00456, loss_moi=0.00813, total_loss=0.0127, train_psnr=17]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00456, loss_moi=0.00813, total_loss=0.0127, train_psnr=17]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00442, loss_moi=0.00842, total_loss=0.0128, train_psnr=16.9]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00431, loss_moi=0.00825, total_loss=0.0126, train_psnr=17.1]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00426, loss_moi=0.00811, total_loss=0.0124, train_psnr=17.1]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00417, loss_moi=0.00794, total_loss=0.0121, train_psnr=17.2]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00423, loss_moi=0.00774, total_loss=0.012, train_psnr=17.2]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.0043, loss_moi=0.00771, total_loss=0.012, train_psnr=17.1]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00433, loss_moi=0.00762, total_loss=0.012, train_psnr=17.2]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00432, loss_moi=0.00748, total_loss=0.0118, train_psnr=17.2]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00427, loss_moi=0.00741, total_loss=0.0117, train_psnr=17.4]
Epoch 1:  40%|████      | 2/5 [00:01&lt;00:01,  1.94it/s, eval_psnr=23.5, loss_mc=0.00417, loss_moi=0.00736, total_loss=0.0115, train_psnr=17.5]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00417, loss_moi=0.00736, total_loss=0.0115, train_psnr=17.5]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00417, loss_moi=0.00736, total_loss=0.0115, train_psnr=17.5]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00409, loss_moi=0.00714, total_loss=0.0112, train_psnr=17.5]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00401, loss_moi=0.00719, total_loss=0.0112, train_psnr=17.5]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00392, loss_moi=0.00738, total_loss=0.0113, train_psnr=17.5]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00383, loss_moi=0.00748, total_loss=0.0113, train_psnr=17.4]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00375, loss_moi=0.00728, total_loss=0.011, train_psnr=17.4]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00369, loss_moi=0.00725, total_loss=0.0109, train_psnr=17.5]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00372, loss_moi=0.00714, total_loss=0.0109, train_psnr=17.5]
Epoch 1:  60%|██████    | 3/5 [00:01&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00367, loss_moi=0.00699, total_loss=0.0107, train_psnr=17.6]
Epoch 1:  60%|██████    | 3/5 [00:02&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00364, loss_moi=0.00698, total_loss=0.0106, train_psnr=17.6]
Epoch 1:  60%|██████    | 3/5 [00:02&lt;00:01,  1.93it/s, eval_psnr=23.5, loss_mc=0.00358, loss_moi=0.00689, total_loss=0.0105, train_psnr=17.8]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00358, loss_moi=0.00689, total_loss=0.0105, train_psnr=17.8]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00358, loss_moi=0.00689, total_loss=0.0105, train_psnr=17.8]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00353, loss_moi=0.00673, total_loss=0.0103, train_psnr=17.8]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.0035, loss_moi=0.00667, total_loss=0.0102, train_psnr=17.9]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00349, loss_moi=0.00657, total_loss=0.0101, train_psnr=17.9]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00344, loss_moi=0.00653, total_loss=0.00997, train_psnr=18]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.0034, loss_moi=0.00643, total_loss=0.00983, train_psnr=18]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00335, loss_moi=0.00635, total_loss=0.0097, train_psnr=18.1]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.0033, loss_moi=0.00643, total_loss=0.00973, train_psnr=18.1]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00326, loss_moi=0.00643, total_loss=0.00969, train_psnr=18.1]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00321, loss_moi=0.00635, total_loss=0.00956, train_psnr=18.2]
Epoch 1:  80%|████████  | 4/5 [00:02&lt;00:00,  1.94it/s, eval_psnr=23.5, loss_mc=0.00315, loss_moi=0.00625, total_loss=0.0094, train_psnr=18.3]
Epoch 1: 100%|██████████| 5/5 [00:02&lt;00:00,  1.93it/s, eval_psnr=23.5, loss_mc=0.00315, loss_moi=0.00625, total_loss=0.0094, train_psnr=18.3]
Epoch 1: 100%|██████████| 5/5 [00:02&lt;00:00,  1.93it/s, eval_psnr=23.5, loss_mc=0.00315, loss_moi=0.00625, total_loss=0.0094, train_psnr=18.3]

ArtifactRemoval(
  (backbone_net): UNet(
    (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (Conv1): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (Conv2): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (Conv3): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (Up3): Sequential(
      (0): Upsample(scale_factor=2.0, mode=&#39;nearest&#39;)
      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
    )
    (Up_conv3): Sequential(
      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (Up2): Sequential(
      (0): Upsample(scale_factor=2.0, mode=&#39;nearest&#39;)
      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
    )
    (Up_conv2): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
    (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)
</pre></div>
</div>
</section>
<section id="test-the-network">
<h2>Test the network<a class="headerlink" href="#test-the-network" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">plot_images</span></a> <span class="o">=</span> <span class="kc">True</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">method</span></a> <span class="o">=</span> <span class="s2">&quot;multioperator_imaging&quot;</span>

<span class="n">test</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">physics</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">physics</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">plot_images</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">plot_images</span></a><span class="p">,</span>
    <span class="n">save_folder</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">RESULTS_DIR</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">method</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_demo_multioperator_imaging_001.png" srcset="../../_images/sphx_glr_demo_multioperator_imaging_001.png" alt="Input, No learning, Recons., GT" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_demo_multioperator_imaging_002.png" srcset="../../_images/sphx_glr_demo_multioperator_imaging_002.png" alt="Input, No learning, Recons., GT" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_demo_multioperator_imaging_003.png" srcset="../../_images/sphx_glr_demo_multioperator_imaging_003.png" alt="Input, No learning, Recons., GT" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_demo_multioperator_imaging_004.png" srcset="../../_images/sphx_glr_demo_multioperator_imaging_004.png" alt="Input, No learning, Recons., GT" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_demo_multioperator_imaging_005.png" srcset="../../_images/sphx_glr_demo_multioperator_imaging_005.png" alt="Input, No learning, Recons., GT" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Processing data of operator 1 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
Processing data of operator 2 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
Processing data of operator 3 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
Processing data of operator 4 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
100%|██████████| 1/1 [00:01&lt;00:00,  1.07s/it]
Processing data of operator 5 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:01&lt;00:00,  1.09s/it]
100%|██████████| 1/1 [00:01&lt;00:00,  1.09s/it]
Processing data of operator 6 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 91.00it/s]
Processing data of operator 7 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 96.95it/s]
Processing data of operator 8 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 86.61it/s]
Processing data of operator 9 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 82.34it/s]
Processing data of operator 10 out of 10

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 99.47it/s]
Test PSNR: No learning rec.: 13.10+-1.74 dB | Model: 20.47+-1.86 dB.

(20.46658115386963, 1.8617128902874014, 13.103665447235107, 1.7379694923885824)
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 8.626 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-self-supervised-learning-demo-multioperator-imaging-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8c415d2c1c1749a7f5be2026c4d75e8b/demo_multioperator_imaging.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">demo_multioperator_imaging.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/0ed8af0d0fd95c7e0dbbaecec30f661a/demo_multioperator_imaging.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">demo_multioperator_imaging.py</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="demo_n2n_denoising.html" class="btn btn-neutral float-left" title="Self-supervised denoising with the Neighbor2Neighbor loss." accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="demo_equivariant_imaging.html" class="btn btn-neutral float-right" title="Self-supervised learning with Equivariant Imaging for MRI." accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>