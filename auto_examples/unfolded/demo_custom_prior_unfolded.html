<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Learned iterative custom prior &mdash; deepinverse 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
    <link rel="shortcut icon" href="../../_static/logo.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script>window.MathJax = {"tex": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}, "macros": {"forw": ["{A\\left({#1}\\right)}", 1], "noise": ["{N\\left({#1}\\right)}", 1], "inverse": ["{R\\left({#1}\\right)}", 1], "inversef": ["{R\\left({#1},{#2}\\right)}", 2], "reg": ["{g\\left({#1}\\right)}", 1], "regname": "g", "sensor": ["{\\eta\\left({#1}\\right)}", 1], "datafid": ["{f\\left({#1},{#2}\\right)}", 2], "datafidname": "f", "distance": ["{d\\left({#1},{#2}\\right)}", 2], "distancename": "d", "denoiser": ["{\\operatorname{D}_{{#2}}\\left({#1}\\right)}", 2], "denoisername": "\\operatorname{D}", "xset": "\\mathcal{X}", "yset": "\\mathcal{Y}", "group": "\\mathcal{G}", "metric": ["{d\\left({#1},{#2}\\right)}", 2], "loss": ["{\\mathcal\\left({#1}\\right)}", 1]}}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Vanilla Unfolded algorithm for super-resolution" href="demo_vanilla_unfolded.html" />
    <link rel="prev" title="Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing" href="demo_LISTA.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/deepinv_logolarge.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.physics.html">Physics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.pnp.html">PnP and RED algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.unfolded.html">Unfolded algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.sampling.html">Diffusion algorithms</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#basics">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#plug-and-play">Plug-and-Play</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#sampling">Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#self-supervised-learning">Self-Supervised Learning</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#unfolded">Unfolded</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="demo_LISTA.html">Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Learned iterative custom prior</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setup-paths-for-data-loading-and-results">Setup paths for data loading and results.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-base-image-datasets-and-degradation-operators">Load base image datasets and degradation operators.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generate-a-dataset-of-compressed-measurements-and-load-it">Generate a dataset of compressed measurements and load it.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-the-unfolded-proximal-gradient-algorithm">Define the unfolded Proximal Gradient algorithm.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-the-training-parameters">Define the training parameters.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#train-the-network">Train the network.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#test-the-network">Test the network.</a></li>
<li class="toctree-l4"><a class="reference internal" href="#plotting-the-weights-of-the-network">Plotting the weights of the network.</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="demo_vanilla_unfolded.html">Vanilla Unfolded algorithm for super-resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_DEQ.html">Deep Equilibrium (DEQ) algorithms for image deblurring</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_learned_primal_dual.html">Learned Primal-Dual algorithm for CT scan.</a></li>
<li class="toctree-l3"><a class="reference internal" href="demo_unfolded_constrained_LISTA.html">Unfolded Chambolle-Pock for constrained image inpainting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.multigpu.html">Using multiple GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.notation.html">Math Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deepinv.contributing.html">How to Contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">deepinverse</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Examples</a></li>
      <li class="breadcrumb-item active">Learned iterative custom prior</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/auto_examples/unfolded/demo_custom_prior_unfolded.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-unfolded-demo-custom-prior-unfolded-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="learned-iterative-custom-prior">
<span id="sphx-glr-auto-examples-unfolded-demo-custom-prior-unfolded-py"></span><h1>Learned iterative custom prior<a class="headerlink" href="#learned-iterative-custom-prior" title="Link to this heading"></a></h1>
<p>This example shows how to implement a learned unrolled proximal gradient descent algorithm with a custom prior function.
The algorithm is trained on a dataset of compressed sensing measurements of MNIST images.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">deepinv</span> <span class="k">as</span> <span class="nn">dinv</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a>
<span class="kn">from</span> <span class="nn">deepinv.optim.data_fidelity</span> <span class="kn">import</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">L2</span></a>
<span class="kn">from</span> <span class="nn">deepinv.optim.prior</span> <span class="kn">import</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Prior</span></a>
<span class="kn">from</span> <span class="nn">deepinv.unfolded</span> <span class="kn">import</span> <span class="n">unfolded_builder</span>
<span class="kn">from</span> <span class="nn">deepinv.training_utils</span> <span class="kn">import</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>
</pre></div>
</div>
<section id="setup-paths-for-data-loading-and-results">
<h2>Setup paths for data loading and results.<a class="headerlink" href="#setup-paths-for-data-loading-and-results" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.Path" title="pathlib.Path" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class"><span class="n">Path</span></a><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ORIGINAL_DATA_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;datasets&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DATA_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;measurements&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">RESULTS_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;results&quot;</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CKPT_DIR</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">BASE_DIR</span></a> <span class="o">/</span> <span class="s2">&quot;ckpts&quot;</span>

<span class="c1"># Set the global random seed from pytorch to ensure reproducibility of the example.</span>
<a href="https://pytorch.org/docs/2.0/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_freer_gpu</span><span class="p">()</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
</pre></div>
</div>
</section>
<section id="load-base-image-datasets-and-degradation-operators">
<h2>Load base image datasets and degradation operators.<a class="headerlink" href="#load-base-image-datasets-and-degradation-operators" title="Link to this heading"></a></h2>
<p>In this example, we use MNIST as the base dataset.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_size</span></a> <span class="o">=</span> <span class="mi">28</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_channels</span></a> <span class="o">=</span> <span class="mi">1</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a> <span class="o">=</span> <span class="s2">&quot;compressed-sensing&quot;</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset_name</span></a> <span class="o">=</span> <span class="s2">&quot;MNIST_train&quot;</span>

<span class="c1"># Generate training and evaluation datasets in HDF5 folders and load them.</span>
<span class="n">train_test_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>
<span class="n">train_base_dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span></a><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ORIGINAL_DATA_DIR</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">train_test_transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">test_base_dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span></a><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ORIGINAL_DATA_DIR</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">train_test_transform</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="generate-a-dataset-of-compressed-measurements-and-load-it">
<h2>Generate a dataset of compressed measurements and load it.<a class="headerlink" href="#generate-a-dataset-of-compressed-measurements-and-load-it" title="Link to this heading"></a></h2>
<p>We use the compressed sensing class from the physics module to generate a dataset of highly-compressed measurements
(10% of the total number of pixels).</p>
<p>The forward operator is defined as <span class="math notranslate nohighlight">\(y = Ax\)</span>
where <span class="math notranslate nohighlight">\(A\)</span> is a (normalized) random Gaussian matrix.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous</span>
<span class="c1"># data loading.</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a> <span class="o">=</span> <span class="mi">4</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span>

<span class="c1"># Generate the compressed sensing measurement operator with 10x under-sampling factor.</span>
<span class="n">physics</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">physics</span><span class="o">.</span><span class="n">CompressedSensing</span></a><span class="p">(</span>
    <span class="n">m</span><span class="o">=</span><span class="mi">78</span><span class="p">,</span> <span class="n">img_shape</span><span class="o">=</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_channels</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_size</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img_size</span></a><span class="p">),</span> <span class="n">fast</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a>
<span class="p">)</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">my_dataset_name</span></a> <span class="o">=</span> <span class="s2">&quot;demo_LICP&quot;</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_images_max</span></a> <span class="o">=</span> <span class="p">(</span>
    <span class="mi">1000</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">200</span>
<span class="p">)</span>  <span class="c1"># maximal number of images used for training</span>
<a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">measurement_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DATA_DIR</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataset_name</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">generated_datasets_path</span></a> <span class="o">=</span> <span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">generate_dataset</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_base_dataset</span><span class="p">,</span>
    <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_base_dataset</span><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <span class="n">save_dir</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">measurement_dir</span></a><span class="p">,</span>
    <span class="n">train_datapoints</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_images_max</span></a><span class="p">,</span>
    <span class="n">test_datapoints</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span>
    <span class="n">dataset_filename</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">my_dataset_name</span></a><span class="p">),</span>
<span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">HDF5Dataset</span></a><span class="p">(</span><span class="n">path</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">generated_datasets_path</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.Dataset" title="torch.utils.data.Dataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">HDF5Dataset</span></a><span class="p">(</span><span class="n">path</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">generated_datasets_path</span></a><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computing train measurement vectors from base dataset...

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:00&lt;00:00, 16.35it/s]
Computing test measurement vectors from base dataset...

  0%|          | 0/2 [00:00&lt;?, ?it/s]
100%|██████████| 2/2 [00:00&lt;00:00, 755.73it/s]
Dataset has been saved in measurements/MNIST_train/compressed-sensing
</pre></div>
</div>
</section>
<section id="define-the-unfolded-proximal-gradient-algorithm">
<h2>Define the unfolded Proximal Gradient algorithm.<a class="headerlink" href="#define-the-unfolded-proximal-gradient-algorithm" title="Link to this heading"></a></h2>
<p>In this example, we propose to minimise a function of the form</p>
<div class="math notranslate nohighlight">
\[\min_x \frac{\lambda}{2} \|y - Ax\|_2^2 + \operatorname{TV}_{\text{smooth}}(x)\]</div>
<p>where <span class="math notranslate nohighlight">\(\operatorname{TV}_{\text{smooth}}\)</span> is a smooth approximation of TV.
The proximal gradient iteration (see also <a class="reference internal" href="../../stubs/deepinv.optim.optim_iterators.PGDIteration.html#deepinv.optim.optim_iterators.PGDIteration" title="deepinv.optim.optim_iterators.PGDIteration"><code class="xref py py-class docutils literal notranslate"><span class="pre">deepinv.optim.optim_iterators.PGDIteration</span></code></a>) is defined as</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[x_{k+1} = \text{prox}_{\gamma \operatorname{TV}_{\text{smooth}}}(x_k - \gamma \lambda A^T (Ax_k - y))\]</div>
</div></blockquote>
<p>where <span class="math notranslate nohighlight">\(\gamma\)</span> is the stepsize and <span class="math notranslate nohighlight">\(\text{prox}_{g}\)</span> is the proximity operator of <span class="math notranslate nohighlight">\(g(x) =\operatorname{TV}_{\text{smooth}}(x)\)</span>.</p>
<p>We first define the prior in a functional form.
If the prior is initialized with a list of length max_iter,
then a distinct weight is trained for each PGD iteration.
For fixed trained model prior across iterations, initialize with a single model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the image gradient operator</span>
<span class="k">def</span> <span class="nf">nabla</span><span class="p">(</span><span class="n">I</span><span class="p">):</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">I</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">G</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.zeros.html#torch.zeros" title="torch.zeros" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><span class="n">I</span><span class="o">.</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">I</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">G</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">I</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">G</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">I</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="n">G</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">I</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">G</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">G</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">I</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">G</span>


<span class="c1"># Define the smooth TV prior as the mse of the image finite difference.</span>
<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">nabla</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">tv_smooth</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.functional.mse_loss.html#torch.nn.functional.mse_loss" title="torch.nn.functional.mse_loss" class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span></a><span class="p">(</span>
        <span class="n">dx</span><span class="p">,</span> <a href="https://pytorch.org/docs/2.0/generated/torch.zeros_like.html#torch.zeros_like" title="torch.zeros_like" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span></a><span class="p">(</span><span class="n">dx</span><span class="p">),</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">tv_smooth</span>


<span class="c1"># Define the prior. A prior instance from :class:`deepinv.priors` can be simply defined with an explicit potential :math:`g` function as such:</span>
<span class="n">prior</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Prior</span></a><span class="p">(</span><span class="n">g</span><span class="o">=</span><span class="n">g</span><span class="p">)</span>

<span class="c1"># We use :meth:`deepinv.unfolded.unfolded_builder` to define the unfolded algorithm</span>
<span class="c1"># and set both the stepsizes of the PGD algorithm :math:`\gamma` (``stepsize``) and the soft</span>
<span class="c1"># thresholding parameters :math:`\lambda` as learnable parameters.</span>
<span class="c1"># These parameters are initialized with a table of length max_iter,</span>
<span class="c1"># yielding a distinct ``stepsize`` and ``g_param`` value for each iteration of the algorithm.</span>
<span class="c1"># For single ``stepsize`` and ``g_param`` shared across iterations, initialize with a single float value.</span>

<span class="c1"># Unrolled optimization algorithm parameters</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">max_iter</span></a> <span class="o">=</span> <span class="mi">5</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lamb</span></a> <span class="o">=</span> <span class="p">[</span>
    <span class="mf">1.0</span>
<span class="p">]</span> <span class="o">*</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">max_iter</span></a>  <span class="c1"># initialization of the regularization parameter. A distinct lamb is trained for each iteration.</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stepsize</span></a> <span class="o">=</span> <span class="p">[</span>
    <span class="mf">1.0</span>
<span class="p">]</span> <span class="o">*</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">max_iter</span></a>  <span class="c1"># initialization of the stepsizes. A distinct stepsize is trained for each iteration.</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_algo</span></a> <span class="o">=</span> <span class="p">{</span>  <span class="c1"># wrap all the restoration parameters in a &#39;params_algo&#39; dictionary</span>
    <span class="s2">&quot;stepsize&quot;</span><span class="p">:</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stepsize</span></a><span class="p">,</span>
    <span class="s2">&quot;lambda&quot;</span><span class="p">:</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">lamb</span></a><span class="p">,</span>
<span class="p">}</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trainable_params</span></a> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;stepsize&quot;</span><span class="p">,</span>
    <span class="s2">&quot;lambda&quot;</span><span class="p">,</span>
<span class="p">]</span>  <span class="c1"># define which parameters from &#39;params_algo&#39; are trainable</span>

<span class="c1"># Select the data fidelity term</span>
<span class="n">data_fidelity</span> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">L2</span></a><span class="p">()</span>

<span class="c1"># Logging parameters</span>
<a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a> <span class="o">=</span> <span class="kc">True</span>
<a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># plot curves and images in Weight&amp;Bias</span>

<span class="c1"># Define the unfolded trainable model.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">unfolded_builder</span><span class="p">(</span>
    <span class="n">iteration</span><span class="o">=</span><span class="s2">&quot;PGD&quot;</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_algo</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_algo</span></a><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trainable_params</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">trainable_params</span></a><span class="p">,</span>
    <span class="n">data_fidelity</span><span class="o">=</span><span class="n">data_fidelity</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">max_iter</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">max_iter</span></a><span class="p">,</span>
    <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
    <span class="n">g_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="define-the-training-parameters">
<h2>Define the training parameters.<a class="headerlink" href="#define-the-training-parameters" title="Link to this heading"></a></h2>
<p>We now define training-related parameters,
number of epochs, optimizer (Adam) and its hyperparameters, and the train and test batch sizes.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training parameters</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a> <span class="o">=</span> <span class="mi">10</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">5</span>
<a href="https://docs.python.org/3.4/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learning_rate</span></a> <span class="o">=</span> <span class="mf">1e-2</span>

<span class="c1"># Choose optimizer and scheduler</span>
<a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">learning_rate</span></a><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># Choose supervised training loss</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://pytorch.org/docs/2.0/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">dinv</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SupLoss</span></a><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">dinv</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">mse</span><span class="p">())]</span>

<span class="c1"># Batch sizes and data loaders</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_batch_size</span></a> <span class="o">=</span> <span class="mi">64</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">8</span>
<a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_batch_size</span></a> <span class="o">=</span> <span class="mi">64</span> <span class="k">if</span> <a href="https://pytorch.org/docs/2.0/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mi">8</span>

<a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_batch_size</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span>
    <span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_batch_size</span></a><span class="p">,</span> <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">num_workers</span></a><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="train-the-network">
<h2>Train the network.<a class="headerlink" href="#train-the-network" title="Link to this heading"></a></h2>
<p>We train the network using the library’s train function.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="o">=</span><a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_dataloader</span></a><span class="p">,</span>
    <span class="n">eval_dataloader</span><span class="o">=</span><a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">epochs</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">losses</span></a><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a><span class="o">=</span><a href="https://pytorch.org/docs/2.0/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optimizer</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <span class="n">save_path</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CKPT_DIR</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a><span class="p">),</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="p">,</span>  <span class="c1"># training visualization can be done in Weight&amp;Bias</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The model has 10 trainable parameters

  0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 1:   0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 1:   0%|          | 0/25 [00:00&lt;?, ?it/s, eval_psnr=11.9, total_loss=0.0757, train_psnr=11.5]
Epoch 1:   4%|▍         | 1/25 [00:00&lt;00:08,  2.76it/s, eval_psnr=11.9, total_loss=0.0757, train_psnr=11.5]
Epoch 1:   4%|▍         | 1/25 [00:00&lt;00:08,  2.76it/s, eval_psnr=11.9, total_loss=0.0757, train_psnr=11.5]
Epoch 1:   4%|▍         | 1/25 [00:00&lt;00:08,  2.76it/s, eval_psnr=11.9, total_loss=0.0873, train_psnr=10.8]
Epoch 1:   8%|▊         | 2/25 [00:00&lt;00:05,  4.42it/s, eval_psnr=11.9, total_loss=0.0873, train_psnr=10.8]
Epoch 1:   8%|▊         | 2/25 [00:00&lt;00:05,  4.42it/s, eval_psnr=11.9, total_loss=0.0873, train_psnr=10.8]
Epoch 1:   8%|▊         | 2/25 [00:00&lt;00:05,  4.42it/s, eval_psnr=11.9, total_loss=0.0817, train_psnr=11.2]
Epoch 1:  12%|█▏        | 3/25 [00:00&lt;00:07,  3.09it/s, eval_psnr=11.9, total_loss=0.0817, train_psnr=11.2]
Epoch 1:  12%|█▏        | 3/25 [00:00&lt;00:07,  3.09it/s, eval_psnr=11.9, total_loss=0.0817, train_psnr=11.2]
Epoch 1:  12%|█▏        | 3/25 [00:01&lt;00:07,  3.09it/s, eval_psnr=11.9, total_loss=0.0849, train_psnr=11.1]
Epoch 1:  16%|█▌        | 4/25 [00:01&lt;00:05,  3.55it/s, eval_psnr=11.9, total_loss=0.0849, train_psnr=11.1]
Epoch 1:  16%|█▌        | 4/25 [00:01&lt;00:05,  3.55it/s, eval_psnr=11.9, total_loss=0.0849, train_psnr=11.1]
Epoch 1:  16%|█▌        | 4/25 [00:01&lt;00:05,  3.55it/s, eval_psnr=11.9, total_loss=0.083, train_psnr=11.1]
Epoch 1:  20%|██        | 5/25 [00:01&lt;00:06,  3.13it/s, eval_psnr=11.9, total_loss=0.083, train_psnr=11.1]
Epoch 1:  20%|██        | 5/25 [00:01&lt;00:06,  3.13it/s, eval_psnr=11.9, total_loss=0.083, train_psnr=11.1]
Epoch 1:  20%|██        | 5/25 [00:01&lt;00:06,  3.13it/s, eval_psnr=11.9, total_loss=0.0851, train_psnr=11]
Epoch 1:  24%|██▍       | 6/25 [00:01&lt;00:05,  3.71it/s, eval_psnr=11.9, total_loss=0.0851, train_psnr=11]
Epoch 1:  24%|██▍       | 6/25 [00:01&lt;00:05,  3.71it/s, eval_psnr=11.9, total_loss=0.0851, train_psnr=11]
Epoch 1:  24%|██▍       | 6/25 [00:02&lt;00:05,  3.71it/s, eval_psnr=11.9, total_loss=0.0822, train_psnr=11.1]
Epoch 1:  28%|██▊       | 7/25 [00:02&lt;00:05,  3.08it/s, eval_psnr=11.9, total_loss=0.0822, train_psnr=11.1]
Epoch 1:  28%|██▊       | 7/25 [00:02&lt;00:05,  3.08it/s, eval_psnr=11.9, total_loss=0.0822, train_psnr=11.1]
Epoch 1:  28%|██▊       | 7/25 [00:02&lt;00:05,  3.08it/s, eval_psnr=11.9, total_loss=0.0806, train_psnr=11.2]
Epoch 1:  32%|███▏      | 8/25 [00:02&lt;00:06,  2.75it/s, eval_psnr=11.9, total_loss=0.0806, train_psnr=11.2]
Epoch 1:  32%|███▏      | 8/25 [00:02&lt;00:06,  2.75it/s, eval_psnr=11.9, total_loss=0.0806, train_psnr=11.2]
Epoch 1:  32%|███▏      | 8/25 [00:02&lt;00:06,  2.75it/s, eval_psnr=11.9, total_loss=0.0804, train_psnr=11.2]
Epoch 1:  36%|███▌      | 9/25 [00:02&lt;00:05,  2.86it/s, eval_psnr=11.9, total_loss=0.0804, train_psnr=11.2]
Epoch 1:  36%|███▌      | 9/25 [00:02&lt;00:05,  2.86it/s, eval_psnr=11.9, total_loss=0.0804, train_psnr=11.2]
Epoch 1:  36%|███▌      | 9/25 [00:03&lt;00:05,  2.86it/s, eval_psnr=11.9, total_loss=0.081, train_psnr=11.2]
Epoch 1:  40%|████      | 10/25 [00:03&lt;00:04,  3.21it/s, eval_psnr=11.9, total_loss=0.081, train_psnr=11.2]
Epoch 1:  40%|████      | 10/25 [00:03&lt;00:04,  3.21it/s, eval_psnr=11.9, total_loss=0.081, train_psnr=11.2]
Epoch 1:  40%|████      | 10/25 [00:03&lt;00:04,  3.21it/s, eval_psnr=11.9, total_loss=0.082, train_psnr=11.1]
Epoch 1:  44%|████▍     | 11/25 [00:03&lt;00:03,  3.61it/s, eval_psnr=11.9, total_loss=0.082, train_psnr=11.1]
Epoch 1:  44%|████▍     | 11/25 [00:03&lt;00:03,  3.61it/s, eval_psnr=11.9, total_loss=0.082, train_psnr=11.1]
Epoch 1:  44%|████▍     | 11/25 [00:03&lt;00:03,  3.61it/s, eval_psnr=11.9, total_loss=0.0815, train_psnr=11.1]
Epoch 1:  48%|████▊     | 12/25 [00:03&lt;00:04,  3.20it/s, eval_psnr=11.9, total_loss=0.0815, train_psnr=11.1]
Epoch 1:  48%|████▊     | 12/25 [00:03&lt;00:04,  3.20it/s, eval_psnr=11.9, total_loss=0.0815, train_psnr=11.1]
Epoch 1:  48%|████▊     | 12/25 [00:03&lt;00:04,  3.20it/s, eval_psnr=11.9, total_loss=0.0827, train_psnr=11.1]
Epoch 1:  52%|█████▏    | 13/25 [00:03&lt;00:03,  3.73it/s, eval_psnr=11.9, total_loss=0.0827, train_psnr=11.1]
Epoch 1:  52%|█████▏    | 13/25 [00:03&lt;00:03,  3.73it/s, eval_psnr=11.9, total_loss=0.0827, train_psnr=11.1]
Epoch 1:  52%|█████▏    | 13/25 [00:04&lt;00:03,  3.73it/s, eval_psnr=11.9, total_loss=0.0831, train_psnr=11.1]
Epoch 1:  56%|█████▌    | 14/25 [00:04&lt;00:03,  3.50it/s, eval_psnr=11.9, total_loss=0.0831, train_psnr=11.1]
Epoch 1:  56%|█████▌    | 14/25 [00:04&lt;00:03,  3.50it/s, eval_psnr=11.9, total_loss=0.0831, train_psnr=11.1]
Epoch 1:  56%|█████▌    | 14/25 [00:04&lt;00:03,  3.50it/s, eval_psnr=11.9, total_loss=0.0827, train_psnr=11.1]
Epoch 1:  60%|██████    | 15/25 [00:04&lt;00:03,  2.91it/s, eval_psnr=11.9, total_loss=0.0827, train_psnr=11.1]
Epoch 1:  60%|██████    | 15/25 [00:04&lt;00:03,  2.91it/s, eval_psnr=11.9, total_loss=0.0827, train_psnr=11.1]
Epoch 1:  60%|██████    | 15/25 [00:05&lt;00:03,  2.91it/s, eval_psnr=11.9, total_loss=0.0829, train_psnr=11.1]
Epoch 1:  64%|██████▍   | 16/25 [00:05&lt;00:03,  2.87it/s, eval_psnr=11.9, total_loss=0.0829, train_psnr=11.1]
Epoch 1:  64%|██████▍   | 16/25 [00:05&lt;00:03,  2.87it/s, eval_psnr=11.9, total_loss=0.0829, train_psnr=11.1]
Epoch 1:  64%|██████▍   | 16/25 [00:05&lt;00:03,  2.87it/s, eval_psnr=11.9, total_loss=0.0832, train_psnr=11.1]
Epoch 1:  68%|██████▊   | 17/25 [00:05&lt;00:02,  3.10it/s, eval_psnr=11.9, total_loss=0.0832, train_psnr=11.1]
Epoch 1:  68%|██████▊   | 17/25 [00:05&lt;00:02,  3.10it/s, eval_psnr=11.9, total_loss=0.0832, train_psnr=11.1]
Epoch 1:  68%|██████▊   | 17/25 [00:05&lt;00:02,  3.10it/s, eval_psnr=11.9, total_loss=0.0832, train_psnr=11.1]
Epoch 1:  72%|███████▏  | 18/25 [00:05&lt;00:02,  2.88it/s, eval_psnr=11.9, total_loss=0.0832, train_psnr=11.1]
Epoch 1:  72%|███████▏  | 18/25 [00:05&lt;00:02,  2.88it/s, eval_psnr=11.9, total_loss=0.0832, train_psnr=11.1]
Epoch 1:  72%|███████▏  | 18/25 [00:05&lt;00:02,  2.88it/s, eval_psnr=11.9, total_loss=0.084, train_psnr=11]
Epoch 1:  76%|███████▌  | 19/25 [00:05&lt;00:01,  3.29it/s, eval_psnr=11.9, total_loss=0.084, train_psnr=11]
Epoch 1:  76%|███████▌  | 19/25 [00:05&lt;00:01,  3.29it/s, eval_psnr=11.9, total_loss=0.084, train_psnr=11]
Epoch 1:  76%|███████▌  | 19/25 [00:06&lt;00:01,  3.29it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  80%|████████  | 20/25 [00:06&lt;00:01,  3.38it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  80%|████████  | 20/25 [00:06&lt;00:01,  3.38it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  80%|████████  | 20/25 [00:06&lt;00:01,  3.38it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  84%|████████▍ | 21/25 [00:06&lt;00:01,  3.04it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  84%|████████▍ | 21/25 [00:06&lt;00:01,  3.04it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  84%|████████▍ | 21/25 [00:07&lt;00:01,  3.04it/s, eval_psnr=11.9, total_loss=0.0843, train_psnr=11]
Epoch 1:  88%|████████▊ | 22/25 [00:07&lt;00:01,  2.71it/s, eval_psnr=11.9, total_loss=0.0843, train_psnr=11]
Epoch 1:  88%|████████▊ | 22/25 [00:07&lt;00:01,  2.71it/s, eval_psnr=11.9, total_loss=0.0843, train_psnr=11]
Epoch 1:  88%|████████▊ | 22/25 [00:07&lt;00:01,  2.71it/s, eval_psnr=11.9, total_loss=0.0845, train_psnr=11]
Epoch 1:  92%|█████████▏| 23/25 [00:07&lt;00:00,  2.76it/s, eval_psnr=11.9, total_loss=0.0845, train_psnr=11]
Epoch 1:  92%|█████████▏| 23/25 [00:07&lt;00:00,  2.76it/s, eval_psnr=11.9, total_loss=0.0845, train_psnr=11]
Epoch 1:  92%|█████████▏| 23/25 [00:07&lt;00:00,  2.76it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  96%|█████████▌| 24/25 [00:07&lt;00:00,  2.66it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  96%|█████████▌| 24/25 [00:07&lt;00:00,  2.66it/s, eval_psnr=11.9, total_loss=0.0847, train_psnr=11]
Epoch 1:  96%|█████████▌| 24/25 [00:08&lt;00:00,  2.66it/s, eval_psnr=11.9, total_loss=0.0842, train_psnr=11]
Epoch 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.49it/s, eval_psnr=11.9, total_loss=0.0842, train_psnr=11]
Epoch 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, eval_psnr=11.9, total_loss=0.0842, train_psnr=11]

  0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 2:   0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 2:   0%|          | 0/25 [00:00&lt;?, ?it/s, eval_psnr=12, total_loss=0.0692, train_psnr=12]
Epoch 2:   4%|▍         | 1/25 [00:00&lt;00:11,  2.14it/s, eval_psnr=12, total_loss=0.0692, train_psnr=12]
Epoch 2:   4%|▍         | 1/25 [00:00&lt;00:11,  2.14it/s, eval_psnr=12, total_loss=0.0692, train_psnr=12]
Epoch 2:   4%|▍         | 1/25 [00:00&lt;00:11,  2.14it/s, eval_psnr=12, total_loss=0.08, train_psnr=11.3]
Epoch 2:   8%|▊         | 2/25 [00:00&lt;00:10,  2.26it/s, eval_psnr=12, total_loss=0.08, train_psnr=11.3]
Epoch 2:   8%|▊         | 2/25 [00:00&lt;00:10,  2.26it/s, eval_psnr=12, total_loss=0.08, train_psnr=11.3]
Epoch 2:   8%|▊         | 2/25 [00:01&lt;00:10,  2.26it/s, eval_psnr=12, total_loss=0.0848, train_psnr=11]
Epoch 2:  12%|█▏        | 3/25 [00:01&lt;00:08,  2.46it/s, eval_psnr=12, total_loss=0.0848, train_psnr=11]
Epoch 2:  12%|█▏        | 3/25 [00:01&lt;00:08,  2.46it/s, eval_psnr=12, total_loss=0.0848, train_psnr=11]
Epoch 2:  12%|█▏        | 3/25 [00:01&lt;00:08,  2.46it/s, eval_psnr=12, total_loss=0.0852, train_psnr=11]
Epoch 2:  16%|█▌        | 4/25 [00:01&lt;00:08,  2.41it/s, eval_psnr=12, total_loss=0.0852, train_psnr=11]
Epoch 2:  16%|█▌        | 4/25 [00:01&lt;00:08,  2.41it/s, eval_psnr=12, total_loss=0.0852, train_psnr=11]
Epoch 2:  16%|█▌        | 4/25 [00:02&lt;00:08,  2.41it/s, eval_psnr=12, total_loss=0.0841, train_psnr=11]
Epoch 2:  20%|██        | 5/25 [00:02&lt;00:08,  2.33it/s, eval_psnr=12, total_loss=0.0841, train_psnr=11]
Epoch 2:  20%|██        | 5/25 [00:02&lt;00:08,  2.33it/s, eval_psnr=12, total_loss=0.0841, train_psnr=11]
Epoch 2:  20%|██        | 5/25 [00:02&lt;00:08,  2.33it/s, eval_psnr=12, total_loss=0.0862, train_psnr=10.9]
Epoch 2:  24%|██▍       | 6/25 [00:02&lt;00:07,  2.41it/s, eval_psnr=12, total_loss=0.0862, train_psnr=10.9]
Epoch 2:  24%|██▍       | 6/25 [00:02&lt;00:07,  2.41it/s, eval_psnr=12, total_loss=0.0862, train_psnr=10.9]
Epoch 2:  24%|██▍       | 6/25 [00:02&lt;00:07,  2.41it/s, eval_psnr=12, total_loss=0.0868, train_psnr=10.9]
Epoch 2:  28%|██▊       | 7/25 [00:02&lt;00:07,  2.33it/s, eval_psnr=12, total_loss=0.0868, train_psnr=10.9]
Epoch 2:  28%|██▊       | 7/25 [00:02&lt;00:07,  2.33it/s, eval_psnr=12, total_loss=0.0868, train_psnr=10.9]
Epoch 2:  28%|██▊       | 7/25 [00:03&lt;00:07,  2.33it/s, eval_psnr=12, total_loss=0.0874, train_psnr=10.9]
Epoch 2:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.29it/s, eval_psnr=12, total_loss=0.0874, train_psnr=10.9]
Epoch 2:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.29it/s, eval_psnr=12, total_loss=0.0874, train_psnr=10.9]
Epoch 2:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.29it/s, eval_psnr=12, total_loss=0.0876, train_psnr=10.9]
Epoch 2:  36%|███▌      | 9/25 [00:03&lt;00:06,  2.35it/s, eval_psnr=12, total_loss=0.0876, train_psnr=10.9]
Epoch 2:  36%|███▌      | 9/25 [00:03&lt;00:06,  2.35it/s, eval_psnr=12, total_loss=0.0876, train_psnr=10.9]
Epoch 2:  36%|███▌      | 9/25 [00:04&lt;00:06,  2.35it/s, eval_psnr=12, total_loss=0.0888, train_psnr=10.8]
Epoch 2:  40%|████      | 10/25 [00:04&lt;00:06,  2.30it/s, eval_psnr=12, total_loss=0.0888, train_psnr=10.8]
Epoch 2:  40%|████      | 10/25 [00:04&lt;00:06,  2.30it/s, eval_psnr=12, total_loss=0.0888, train_psnr=10.8]
Epoch 2:  40%|████      | 10/25 [00:04&lt;00:06,  2.30it/s, eval_psnr=12, total_loss=0.088, train_psnr=10.9]
Epoch 2:  44%|████▍     | 11/25 [00:04&lt;00:06,  2.26it/s, eval_psnr=12, total_loss=0.088, train_psnr=10.9]
Epoch 2:  44%|████▍     | 11/25 [00:04&lt;00:06,  2.26it/s, eval_psnr=12, total_loss=0.088, train_psnr=10.9]
Epoch 2:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.26it/s, eval_psnr=12, total_loss=0.0871, train_psnr=10.9]
Epoch 2:  48%|████▊     | 12/25 [00:05&lt;00:05,  2.23it/s, eval_psnr=12, total_loss=0.0871, train_psnr=10.9]
Epoch 2:  48%|████▊     | 12/25 [00:05&lt;00:05,  2.23it/s, eval_psnr=12, total_loss=0.0871, train_psnr=10.9]
Epoch 2:  48%|████▊     | 12/25 [00:05&lt;00:05,  2.23it/s, eval_psnr=12, total_loss=0.0864, train_psnr=10.9]
Epoch 2:  52%|█████▏    | 13/25 [00:05&lt;00:05,  2.19it/s, eval_psnr=12, total_loss=0.0864, train_psnr=10.9]
Epoch 2:  52%|█████▏    | 13/25 [00:05&lt;00:05,  2.19it/s, eval_psnr=12, total_loss=0.0864, train_psnr=10.9]
Epoch 2:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.19it/s, eval_psnr=12, total_loss=0.0849, train_psnr=11]
Epoch 2:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.18it/s, eval_psnr=12, total_loss=0.0849, train_psnr=11]
Epoch 2:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.18it/s, eval_psnr=12, total_loss=0.0849, train_psnr=11]
Epoch 2:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.18it/s, eval_psnr=12, total_loss=0.0852, train_psnr=11]
Epoch 2:  60%|██████    | 15/25 [00:06&lt;00:04,  2.18it/s, eval_psnr=12, total_loss=0.0852, train_psnr=11]
Epoch 2:  60%|██████    | 15/25 [00:06&lt;00:04,  2.18it/s, eval_psnr=12, total_loss=0.0852, train_psnr=11]
Epoch 2:  60%|██████    | 15/25 [00:07&lt;00:04,  2.18it/s, eval_psnr=12, total_loss=0.085, train_psnr=11]
Epoch 2:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.17it/s, eval_psnr=12, total_loss=0.085, train_psnr=11]
Epoch 2:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.17it/s, eval_psnr=12, total_loss=0.085, train_psnr=11]
Epoch 2:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.17it/s, eval_psnr=12, total_loss=0.0837, train_psnr=11.1]
Epoch 2:  68%|██████▊   | 17/25 [00:07&lt;00:03,  2.15it/s, eval_psnr=12, total_loss=0.0837, train_psnr=11.1]
Epoch 2:  68%|██████▊   | 17/25 [00:07&lt;00:03,  2.15it/s, eval_psnr=12, total_loss=0.0837, train_psnr=11.1]
Epoch 2:  68%|██████▊   | 17/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12, total_loss=0.0837, train_psnr=11.1]
Epoch 2:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12, total_loss=0.0837, train_psnr=11.1]
Epoch 2:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12, total_loss=0.0837, train_psnr=11.1]
Epoch 2:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12, total_loss=0.0834, train_psnr=11.1]
Epoch 2:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.16it/s, eval_psnr=12, total_loss=0.0834, train_psnr=11.1]
Epoch 2:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.16it/s, eval_psnr=12, total_loss=0.0834, train_psnr=11.1]
Epoch 2:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.16it/s, eval_psnr=12, total_loss=0.0835, train_psnr=11.1]
Epoch 2:  80%|████████  | 20/25 [00:08&lt;00:02,  2.16it/s, eval_psnr=12, total_loss=0.0835, train_psnr=11.1]
Epoch 2:  80%|████████  | 20/25 [00:08&lt;00:02,  2.16it/s, eval_psnr=12, total_loss=0.0835, train_psnr=11.1]
Epoch 2:  80%|████████  | 20/25 [00:09&lt;00:02,  2.16it/s, eval_psnr=12, total_loss=0.0831, train_psnr=11.1]
Epoch 2:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.15it/s, eval_psnr=12, total_loss=0.0831, train_psnr=11.1]
Epoch 2:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.15it/s, eval_psnr=12, total_loss=0.0831, train_psnr=11.1]
Epoch 2:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.15it/s, eval_psnr=12, total_loss=0.083, train_psnr=11.1]
Epoch 2:  88%|████████▊ | 22/25 [00:09&lt;00:01,  2.15it/s, eval_psnr=12, total_loss=0.083, train_psnr=11.1]
Epoch 2:  88%|████████▊ | 22/25 [00:09&lt;00:01,  2.15it/s, eval_psnr=12, total_loss=0.083, train_psnr=11.1]
Epoch 2:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.15it/s, eval_psnr=12, total_loss=0.083, train_psnr=11.1]
Epoch 2:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12, total_loss=0.083, train_psnr=11.1]
Epoch 2:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12, total_loss=0.083, train_psnr=11.1]
Epoch 2:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12, total_loss=0.0824, train_psnr=11.1]
Epoch 2:  96%|█████████▌| 24/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12, total_loss=0.0824, train_psnr=11.1]
Epoch 2:  96%|█████████▌| 24/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12, total_loss=0.0824, train_psnr=11.1]
Epoch 2:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.15it/s, eval_psnr=12, total_loss=0.0824, train_psnr=11.1]
Epoch 2: 100%|██████████| 25/25 [00:11&lt;00:00,  2.16it/s, eval_psnr=12, total_loss=0.0824, train_psnr=11.1]
Epoch 2: 100%|██████████| 25/25 [00:11&lt;00:00,  2.22it/s, eval_psnr=12, total_loss=0.0824, train_psnr=11.1]

  0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 3:   0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 3:   0%|          | 0/25 [00:00&lt;?, ?it/s, eval_psnr=12.1, total_loss=0.0874, train_psnr=10.9]
Epoch 3:   4%|▍         | 1/25 [00:00&lt;00:11,  2.12it/s, eval_psnr=12.1, total_loss=0.0874, train_psnr=10.9]
Epoch 3:   4%|▍         | 1/25 [00:00&lt;00:11,  2.12it/s, eval_psnr=12.1, total_loss=0.0874, train_psnr=10.9]
Epoch 3:   4%|▍         | 1/25 [00:00&lt;00:11,  2.12it/s, eval_psnr=12.1, total_loss=0.0804, train_psnr=11.2]
Epoch 3:   8%|▊         | 2/25 [00:00&lt;00:10,  2.15it/s, eval_psnr=12.1, total_loss=0.0804, train_psnr=11.2]
Epoch 3:   8%|▊         | 2/25 [00:00&lt;00:10,  2.15it/s, eval_psnr=12.1, total_loss=0.0804, train_psnr=11.2]
Epoch 3:   8%|▊         | 2/25 [00:01&lt;00:10,  2.15it/s, eval_psnr=12.1, total_loss=0.0839, train_psnr=11.1]
Epoch 3:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.13it/s, eval_psnr=12.1, total_loss=0.0839, train_psnr=11.1]
Epoch 3:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.13it/s, eval_psnr=12.1, total_loss=0.0839, train_psnr=11.1]
Epoch 3:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.13it/s, eval_psnr=12.1, total_loss=0.0848, train_psnr=11]
Epoch 3:  16%|█▌        | 4/25 [00:01&lt;00:09,  2.14it/s, eval_psnr=12.1, total_loss=0.0848, train_psnr=11]
Epoch 3:  16%|█▌        | 4/25 [00:01&lt;00:09,  2.14it/s, eval_psnr=12.1, total_loss=0.0848, train_psnr=11]
Epoch 3:  16%|█▌        | 4/25 [00:02&lt;00:09,  2.14it/s, eval_psnr=12.1, total_loss=0.0843, train_psnr=11]
Epoch 3:  20%|██        | 5/25 [00:02&lt;00:09,  2.12it/s, eval_psnr=12.1, total_loss=0.0843, train_psnr=11]
Epoch 3:  20%|██        | 5/25 [00:02&lt;00:09,  2.12it/s, eval_psnr=12.1, total_loss=0.0843, train_psnr=11]
Epoch 3:  20%|██        | 5/25 [00:02&lt;00:09,  2.12it/s, eval_psnr=12.1, total_loss=0.0841, train_psnr=11]
Epoch 3:  24%|██▍       | 6/25 [00:02&lt;00:08,  2.14it/s, eval_psnr=12.1, total_loss=0.0841, train_psnr=11]
Epoch 3:  24%|██▍       | 6/25 [00:02&lt;00:08,  2.14it/s, eval_psnr=12.1, total_loss=0.0841, train_psnr=11]
Epoch 3:  24%|██▍       | 6/25 [00:03&lt;00:08,  2.14it/s, eval_psnr=12.1, total_loss=0.0843, train_psnr=11]
Epoch 3:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.14it/s, eval_psnr=12.1, total_loss=0.0843, train_psnr=11]
Epoch 3:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.14it/s, eval_psnr=12.1, total_loss=0.0843, train_psnr=11]
Epoch 3:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.14it/s, eval_psnr=12.1, total_loss=0.0829, train_psnr=11.1]
Epoch 3:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.15it/s, eval_psnr=12.1, total_loss=0.0829, train_psnr=11.1]
Epoch 3:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.15it/s, eval_psnr=12.1, total_loss=0.0829, train_psnr=11.1]
Epoch 3:  32%|███▏      | 8/25 [00:04&lt;00:07,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  40%|████      | 10/25 [00:04&lt;00:06,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  40%|████      | 10/25 [00:04&lt;00:06,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  40%|████      | 10/25 [00:05&lt;00:06,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  48%|████▊     | 12/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  48%|████▊     | 12/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  48%|████▊     | 12/25 [00:06&lt;00:06,  2.16it/s, eval_psnr=12.1, total_loss=0.0826, train_psnr=11.1]
Epoch 3:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.1, total_loss=0.0826, train_psnr=11.1]
Epoch 3:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.1, total_loss=0.0826, train_psnr=11.1]
Epoch 3:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.1, total_loss=0.0832, train_psnr=11.1]
Epoch 3:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.1, total_loss=0.0832, train_psnr=11.1]
Epoch 3:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.1, total_loss=0.0832, train_psnr=11.1]
Epoch 3:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  60%|██████    | 15/25 [00:06&lt;00:04,  2.16it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  60%|██████    | 15/25 [00:06&lt;00:04,  2.16it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  60%|██████    | 15/25 [00:07&lt;00:04,  2.16it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.14it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.14it/s, eval_psnr=12.1, total_loss=0.0823, train_psnr=11.1]
Epoch 3:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.14it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  68%|██████▊   | 17/25 [00:07&lt;00:03,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  68%|██████▊   | 17/25 [00:07&lt;00:03,  2.15it/s, eval_psnr=12.1, total_loss=0.0824, train_psnr=11.1]
Epoch 3:  68%|██████▊   | 17/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12.1, total_loss=0.0828, train_psnr=11.1]
Epoch 3:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12.1, total_loss=0.0828, train_psnr=11.1]
Epoch 3:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12.1, total_loss=0.0828, train_psnr=11.1]
Epoch 3:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12.1, total_loss=0.0822, train_psnr=11.1]
Epoch 3:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.15it/s, eval_psnr=12.1, total_loss=0.0822, train_psnr=11.1]
Epoch 3:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.15it/s, eval_psnr=12.1, total_loss=0.0822, train_psnr=11.1]
Epoch 3:  76%|███████▌  | 19/25 [00:09&lt;00:02,  2.15it/s, eval_psnr=12.1, total_loss=0.0818, train_psnr=11.1]
Epoch 3:  80%|████████  | 20/25 [00:09&lt;00:02,  2.16it/s, eval_psnr=12.1, total_loss=0.0818, train_psnr=11.1]
Epoch 3:  80%|████████  | 20/25 [00:09&lt;00:02,  2.16it/s, eval_psnr=12.1, total_loss=0.0818, train_psnr=11.1]
Epoch 3:  80%|████████  | 20/25 [00:09&lt;00:02,  2.16it/s, eval_psnr=12.1, total_loss=0.0812, train_psnr=11.2]
Epoch 3:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.14it/s, eval_psnr=12.1, total_loss=0.0812, train_psnr=11.2]
Epoch 3:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.14it/s, eval_psnr=12.1, total_loss=0.0812, train_psnr=11.2]
Epoch 3:  84%|████████▍ | 21/25 [00:10&lt;00:01,  2.14it/s, eval_psnr=12.1, total_loss=0.0811, train_psnr=11.2]
Epoch 3:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.15it/s, eval_psnr=12.1, total_loss=0.0811, train_psnr=11.2]
Epoch 3:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.15it/s, eval_psnr=12.1, total_loss=0.0811, train_psnr=11.2]
Epoch 3:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.15it/s, eval_psnr=12.1, total_loss=0.0808, train_psnr=11.2]
Epoch 3:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12.1, total_loss=0.0808, train_psnr=11.2]
Epoch 3:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12.1, total_loss=0.0808, train_psnr=11.2]
Epoch 3:  92%|█████████▏| 23/25 [00:11&lt;00:00,  2.15it/s, eval_psnr=12.1, total_loss=0.0808, train_psnr=11.2]
Epoch 3:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.18it/s, eval_psnr=12.1, total_loss=0.0808, train_psnr=11.2]
Epoch 3:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.18it/s, eval_psnr=12.1, total_loss=0.0808, train_psnr=11.2]
Epoch 3:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.18it/s, eval_psnr=12.1, total_loss=0.0812, train_psnr=11.2]
Epoch 3: 100%|██████████| 25/25 [00:11&lt;00:00,  2.19it/s, eval_psnr=12.1, total_loss=0.0812, train_psnr=11.2]
Epoch 3: 100%|██████████| 25/25 [00:11&lt;00:00,  2.16it/s, eval_psnr=12.1, total_loss=0.0812, train_psnr=11.2]

  0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 4:   0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 4:   0%|          | 0/25 [00:00&lt;?, ?it/s, eval_psnr=12.2, total_loss=0.0747, train_psnr=11.7]
Epoch 4:   4%|▍         | 1/25 [00:00&lt;00:10,  2.20it/s, eval_psnr=12.2, total_loss=0.0747, train_psnr=11.7]
Epoch 4:   4%|▍         | 1/25 [00:00&lt;00:10,  2.20it/s, eval_psnr=12.2, total_loss=0.0747, train_psnr=11.7]
Epoch 4:   4%|▍         | 1/25 [00:00&lt;00:10,  2.20it/s, eval_psnr=12.2, total_loss=0.0776, train_psnr=11.5]
Epoch 4:   8%|▊         | 2/25 [00:00&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.0776, train_psnr=11.5]
Epoch 4:   8%|▊         | 2/25 [00:00&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.0776, train_psnr=11.5]
Epoch 4:   8%|▊         | 2/25 [00:01&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.3]
Epoch 4:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.18it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.3]
Epoch 4:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.18it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.3]
Epoch 4:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.18it/s, eval_psnr=12.2, total_loss=0.0784, train_psnr=11.3]
Epoch 4:  16%|█▌        | 4/25 [00:01&lt;00:09,  2.15it/s, eval_psnr=12.2, total_loss=0.0784, train_psnr=11.3]
Epoch 4:  16%|█▌        | 4/25 [00:01&lt;00:09,  2.15it/s, eval_psnr=12.2, total_loss=0.0784, train_psnr=11.3]
Epoch 4:  16%|█▌        | 4/25 [00:02&lt;00:09,  2.15it/s, eval_psnr=12.2, total_loss=0.0798, train_psnr=11.2]
Epoch 4:  20%|██        | 5/25 [00:02&lt;00:09,  2.15it/s, eval_psnr=12.2, total_loss=0.0798, train_psnr=11.2]
Epoch 4:  20%|██        | 5/25 [00:02&lt;00:09,  2.15it/s, eval_psnr=12.2, total_loss=0.0798, train_psnr=11.2]
Epoch 4:  20%|██        | 5/25 [00:02&lt;00:09,  2.15it/s, eval_psnr=12.2, total_loss=0.0785, train_psnr=11.3]
Epoch 4:  24%|██▍       | 6/25 [00:02&lt;00:08,  2.15it/s, eval_psnr=12.2, total_loss=0.0785, train_psnr=11.3]
Epoch 4:  24%|██▍       | 6/25 [00:02&lt;00:08,  2.15it/s, eval_psnr=12.2, total_loss=0.0785, train_psnr=11.3]
Epoch 4:  24%|██▍       | 6/25 [00:03&lt;00:08,  2.15it/s, eval_psnr=12.2, total_loss=0.0814, train_psnr=11.1]
Epoch 4:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.16it/s, eval_psnr=12.2, total_loss=0.0814, train_psnr=11.1]
Epoch 4:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.16it/s, eval_psnr=12.2, total_loss=0.0814, train_psnr=11.1]
Epoch 4:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.16it/s, eval_psnr=12.2, total_loss=0.0826, train_psnr=11.1]
Epoch 4:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.14it/s, eval_psnr=12.2, total_loss=0.0826, train_psnr=11.1]
Epoch 4:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.14it/s, eval_psnr=12.2, total_loss=0.0826, train_psnr=11.1]
Epoch 4:  32%|███▏      | 8/25 [00:04&lt;00:07,  2.14it/s, eval_psnr=12.2, total_loss=0.0821, train_psnr=11.1]
Epoch 4:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.15it/s, eval_psnr=12.2, total_loss=0.0821, train_psnr=11.1]
Epoch 4:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.15it/s, eval_psnr=12.2, total_loss=0.0821, train_psnr=11.1]
Epoch 4:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.15it/s, eval_psnr=12.2, total_loss=0.0807, train_psnr=11.2]
Epoch 4:  40%|████      | 10/25 [00:04&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0807, train_psnr=11.2]
Epoch 4:  40%|████      | 10/25 [00:04&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0807, train_psnr=11.2]
Epoch 4:  40%|████      | 10/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]
Epoch 4:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]
Epoch 4:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]
Epoch 4:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.2]
Epoch 4:  48%|████▊     | 12/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.2]
Epoch 4:  48%|████▊     | 12/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.2]
Epoch 4:  48%|████▊     | 12/25 [00:06&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0824, train_psnr=11.1]
Epoch 4:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0824, train_psnr=11.1]
Epoch 4:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0824, train_psnr=11.1]
Epoch 4:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.1]
Epoch 4:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.1]
Epoch 4:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.1]
Epoch 4:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0803, train_psnr=11.2]
Epoch 4:  60%|██████    | 15/25 [00:06&lt;00:04,  2.16it/s, eval_psnr=12.2, total_loss=0.0803, train_psnr=11.2]
Epoch 4:  60%|██████    | 15/25 [00:06&lt;00:04,  2.16it/s, eval_psnr=12.2, total_loss=0.0803, train_psnr=11.2]
Epoch 4:  60%|██████    | 15/25 [00:07&lt;00:04,  2.16it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.1]
Epoch 4:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.16it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.1]
Epoch 4:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.16it/s, eval_psnr=12.2, total_loss=0.0816, train_psnr=11.1]
Epoch 4:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.16it/s, eval_psnr=12.2, total_loss=0.0817, train_psnr=11.1]
Epoch 4:  68%|██████▊   | 17/25 [00:07&lt;00:03,  2.16it/s, eval_psnr=12.2, total_loss=0.0817, train_psnr=11.1]
Epoch 4:  68%|██████▊   | 17/25 [00:07&lt;00:03,  2.16it/s, eval_psnr=12.2, total_loss=0.0817, train_psnr=11.1]
Epoch 4:  68%|██████▊   | 17/25 [00:08&lt;00:03,  2.16it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 4:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 4:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 4:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12.2, total_loss=0.0811, train_psnr=11.2]
Epoch 4:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.14it/s, eval_psnr=12.2, total_loss=0.0811, train_psnr=11.2]
Epoch 4:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.14it/s, eval_psnr=12.2, total_loss=0.0811, train_psnr=11.2]
Epoch 4:  76%|███████▌  | 19/25 [00:09&lt;00:02,  2.14it/s, eval_psnr=12.2, total_loss=0.0815, train_psnr=11.1]
Epoch 4:  80%|████████  | 20/25 [00:09&lt;00:02,  2.14it/s, eval_psnr=12.2, total_loss=0.0815, train_psnr=11.1]
Epoch 4:  80%|████████  | 20/25 [00:09&lt;00:02,  2.14it/s, eval_psnr=12.2, total_loss=0.0815, train_psnr=11.1]
Epoch 4:  80%|████████  | 20/25 [00:09&lt;00:02,  2.14it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]
Epoch 4:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.15it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]
Epoch 4:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.15it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]
Epoch 4:  84%|████████▍ | 21/25 [00:10&lt;00:01,  2.15it/s, eval_psnr=12.2, total_loss=0.0811, train_psnr=11.2]
Epoch 4:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.15it/s, eval_psnr=12.2, total_loss=0.0811, train_psnr=11.2]
Epoch 4:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.15it/s, eval_psnr=12.2, total_loss=0.0811, train_psnr=11.2]
Epoch 4:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.15it/s, eval_psnr=12.2, total_loss=0.0805, train_psnr=11.2]
Epoch 4:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12.2, total_loss=0.0805, train_psnr=11.2]
Epoch 4:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.15it/s, eval_psnr=12.2, total_loss=0.0805, train_psnr=11.2]
Epoch 4:  92%|█████████▏| 23/25 [00:11&lt;00:00,  2.15it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 4:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.19it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 4:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.19it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 4:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.19it/s, eval_psnr=12.2, total_loss=0.0809, train_psnr=11.2]
Epoch 4: 100%|██████████| 25/25 [00:11&lt;00:00,  2.21it/s, eval_psnr=12.2, total_loss=0.0809, train_psnr=11.2]
Epoch 4: 100%|██████████| 25/25 [00:11&lt;00:00,  2.16it/s, eval_psnr=12.2, total_loss=0.0809, train_psnr=11.2]

  0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 5:   0%|          | 0/25 [00:00&lt;?, ?it/s]
Epoch 5:   0%|          | 0/25 [00:00&lt;?, ?it/s, eval_psnr=12.2, total_loss=0.077, train_psnr=11.4]
Epoch 5:   4%|▍         | 1/25 [00:00&lt;00:11,  2.17it/s, eval_psnr=12.2, total_loss=0.077, train_psnr=11.4]
Epoch 5:   4%|▍         | 1/25 [00:00&lt;00:11,  2.17it/s, eval_psnr=12.2, total_loss=0.077, train_psnr=11.4]
Epoch 5:   4%|▍         | 1/25 [00:00&lt;00:11,  2.17it/s, eval_psnr=12.2, total_loss=0.0711, train_psnr=11.8]
Epoch 5:   8%|▊         | 2/25 [00:00&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.0711, train_psnr=11.8]
Epoch 5:   8%|▊         | 2/25 [00:00&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.0711, train_psnr=11.8]
Epoch 5:   8%|▊         | 2/25 [00:01&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.0767, train_psnr=11.4]
Epoch 5:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.0767, train_psnr=11.4]
Epoch 5:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.0767, train_psnr=11.4]
Epoch 5:  12%|█▏        | 3/25 [00:01&lt;00:10,  2.17it/s, eval_psnr=12.2, total_loss=0.0763, train_psnr=11.4]
Epoch 5:  16%|█▌        | 4/25 [00:01&lt;00:09,  2.17it/s, eval_psnr=12.2, total_loss=0.0763, train_psnr=11.4]
Epoch 5:  16%|█▌        | 4/25 [00:01&lt;00:09,  2.17it/s, eval_psnr=12.2, total_loss=0.0763, train_psnr=11.4]
Epoch 5:  16%|█▌        | 4/25 [00:02&lt;00:09,  2.17it/s, eval_psnr=12.2, total_loss=0.076, train_psnr=11.4]
Epoch 5:  20%|██        | 5/25 [00:02&lt;00:09,  2.17it/s, eval_psnr=12.2, total_loss=0.076, train_psnr=11.4]
Epoch 5:  20%|██        | 5/25 [00:02&lt;00:09,  2.17it/s, eval_psnr=12.2, total_loss=0.076, train_psnr=11.4]
Epoch 5:  20%|██        | 5/25 [00:02&lt;00:09,  2.17it/s, eval_psnr=12.2, total_loss=0.0754, train_psnr=11.4]
Epoch 5:  24%|██▍       | 6/25 [00:02&lt;00:08,  2.17it/s, eval_psnr=12.2, total_loss=0.0754, train_psnr=11.4]
Epoch 5:  24%|██▍       | 6/25 [00:02&lt;00:08,  2.17it/s, eval_psnr=12.2, total_loss=0.0754, train_psnr=11.4]
Epoch 5:  24%|██▍       | 6/25 [00:03&lt;00:08,  2.17it/s, eval_psnr=12.2, total_loss=0.0743, train_psnr=11.5]
Epoch 5:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.16it/s, eval_psnr=12.2, total_loss=0.0743, train_psnr=11.5]
Epoch 5:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.16it/s, eval_psnr=12.2, total_loss=0.0743, train_psnr=11.5]
Epoch 5:  28%|██▊       | 7/25 [00:03&lt;00:08,  2.16it/s, eval_psnr=12.2, total_loss=0.0752, train_psnr=11.4]
Epoch 5:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.16it/s, eval_psnr=12.2, total_loss=0.0752, train_psnr=11.4]
Epoch 5:  32%|███▏      | 8/25 [00:03&lt;00:07,  2.16it/s, eval_psnr=12.2, total_loss=0.0752, train_psnr=11.4]
Epoch 5:  32%|███▏      | 8/25 [00:04&lt;00:07,  2.16it/s, eval_psnr=12.2, total_loss=0.0772, train_psnr=11.3]
Epoch 5:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.16it/s, eval_psnr=12.2, total_loss=0.0772, train_psnr=11.3]
Epoch 5:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.16it/s, eval_psnr=12.2, total_loss=0.0772, train_psnr=11.3]
Epoch 5:  36%|███▌      | 9/25 [00:04&lt;00:07,  2.16it/s, eval_psnr=12.2, total_loss=0.0781, train_psnr=11.3]
Epoch 5:  40%|████      | 10/25 [00:04&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0781, train_psnr=11.3]
Epoch 5:  40%|████      | 10/25 [00:04&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0781, train_psnr=11.3]
Epoch 5:  40%|████      | 10/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0787, train_psnr=11.3]
Epoch 5:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0787, train_psnr=11.3]
Epoch 5:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0787, train_psnr=11.3]
Epoch 5:  44%|████▍     | 11/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0787, train_psnr=11.3]
Epoch 5:  48%|████▊     | 12/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0787, train_psnr=11.3]
Epoch 5:  48%|████▊     | 12/25 [00:05&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0787, train_psnr=11.3]
Epoch 5:  48%|████▊     | 12/25 [00:06&lt;00:06,  2.16it/s, eval_psnr=12.2, total_loss=0.0797, train_psnr=11.2]
Epoch 5:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.2, total_loss=0.0797, train_psnr=11.2]
Epoch 5:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.2, total_loss=0.0797, train_psnr=11.2]
Epoch 5:  52%|█████▏    | 13/25 [00:06&lt;00:05,  2.16it/s, eval_psnr=12.2, total_loss=0.0789, train_psnr=11.3]
Epoch 5:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0789, train_psnr=11.3]
Epoch 5:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0789, train_psnr=11.3]
Epoch 5:  56%|█████▌    | 14/25 [00:06&lt;00:05,  2.15it/s, eval_psnr=12.2, total_loss=0.0792, train_psnr=11.3]
Epoch 5:  60%|██████    | 15/25 [00:06&lt;00:04,  2.15it/s, eval_psnr=12.2, total_loss=0.0792, train_psnr=11.3]
Epoch 5:  60%|██████    | 15/25 [00:06&lt;00:04,  2.15it/s, eval_psnr=12.2, total_loss=0.0792, train_psnr=11.3]
Epoch 5:  60%|██████    | 15/25 [00:07&lt;00:04,  2.15it/s, eval_psnr=12.2, total_loss=0.0786, train_psnr=11.3]
Epoch 5:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.14it/s, eval_psnr=12.2, total_loss=0.0786, train_psnr=11.3]
Epoch 5:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.14it/s, eval_psnr=12.2, total_loss=0.0786, train_psnr=11.3]
Epoch 5:  64%|██████▍   | 16/25 [00:07&lt;00:04,  2.14it/s, eval_psnr=12.2, total_loss=0.0788, train_psnr=11.3]
Epoch 5:  68%|██████▊   | 17/25 [00:07&lt;00:03,  2.15it/s, eval_psnr=12.2, total_loss=0.0788, train_psnr=11.3]
Epoch 5:  68%|██████▊   | 17/25 [00:07&lt;00:03,  2.15it/s, eval_psnr=12.2, total_loss=0.0788, train_psnr=11.3]
Epoch 5:  68%|██████▊   | 17/25 [00:08&lt;00:03,  2.15it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.2]
Epoch 5:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.13it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.2]
Epoch 5:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.13it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.2]
Epoch 5:  72%|███████▏  | 18/25 [00:08&lt;00:03,  2.13it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.2]
Epoch 5:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.13it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.2]
Epoch 5:  76%|███████▌  | 19/25 [00:08&lt;00:02,  2.13it/s, eval_psnr=12.2, total_loss=0.08, train_psnr=11.2]
Epoch 5:  76%|███████▌  | 19/25 [00:09&lt;00:02,  2.13it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 5:  80%|████████  | 20/25 [00:09&lt;00:02,  2.12it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 5:  80%|████████  | 20/25 [00:09&lt;00:02,  2.12it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 5:  80%|████████  | 20/25 [00:09&lt;00:02,  2.12it/s, eval_psnr=12.2, total_loss=0.0812, train_psnr=11.2]
Epoch 5:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.14it/s, eval_psnr=12.2, total_loss=0.0812, train_psnr=11.2]
Epoch 5:  84%|████████▍ | 21/25 [00:09&lt;00:01,  2.14it/s, eval_psnr=12.2, total_loss=0.0812, train_psnr=11.2]
Epoch 5:  84%|████████▍ | 21/25 [00:10&lt;00:01,  2.14it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 5:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.14it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 5:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.14it/s, eval_psnr=12.2, total_loss=0.081, train_psnr=11.2]
Epoch 5:  88%|████████▊ | 22/25 [00:10&lt;00:01,  2.14it/s, eval_psnr=12.2, total_loss=0.0808, train_psnr=11.2]
Epoch 5:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.12it/s, eval_psnr=12.2, total_loss=0.0808, train_psnr=11.2]
Epoch 5:  92%|█████████▏| 23/25 [00:10&lt;00:00,  2.12it/s, eval_psnr=12.2, total_loss=0.0808, train_psnr=11.2]
Epoch 5:  92%|█████████▏| 23/25 [00:11&lt;00:00,  2.12it/s, eval_psnr=12.2, total_loss=0.0804, train_psnr=11.2]
Epoch 5:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.12it/s, eval_psnr=12.2, total_loss=0.0804, train_psnr=11.2]
Epoch 5:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.12it/s, eval_psnr=12.2, total_loss=0.0804, train_psnr=11.2]
Epoch 5:  96%|█████████▌| 24/25 [00:11&lt;00:00,  2.12it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]
Epoch 5: 100%|██████████| 25/25 [00:11&lt;00:00,  2.12it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]
Epoch 5: 100%|██████████| 25/25 [00:11&lt;00:00,  2.15it/s, eval_psnr=12.2, total_loss=0.0806, train_psnr=11.2]

BaseUnfold(
  (fixed_point): FixedPoint(
    (iterator): PGDIteration(
      (f_step): fStepPGD()
      (g_step): gStepPGD()
    )
  )
  (init_params_algo): ParameterDict(
      (beta): Object of type: list
      (g_param): Object of type: list
      (lambda): Object of type: ParameterList
      (stepsize): Object of type: ParameterList
    (lambda): ParameterList(
        (0): Parameter containing: [torch.float32 of size ]
        (1): Parameter containing: [torch.float32 of size ]
        (2): Parameter containing: [torch.float32 of size ]
        (3): Parameter containing: [torch.float32 of size ]
        (4): Parameter containing: [torch.float32 of size ]
    )
    (stepsize): ParameterList(
        (0): Parameter containing: [torch.float32 of size ]
        (1): Parameter containing: [torch.float32 of size ]
        (2): Parameter containing: [torch.float32 of size ]
        (3): Parameter containing: [torch.float32 of size ]
        (4): Parameter containing: [torch.float32 of size ]
    )
  )
  (params_algo): ParameterDict(
      (beta): Object of type: list
      (g_param): Object of type: list
      (lambda): Object of type: ParameterList
      (stepsize): Object of type: ParameterList
    (lambda): ParameterList(
        (0): Parameter containing: [torch.float32 of size ]
        (1): Parameter containing: [torch.float32 of size ]
        (2): Parameter containing: [torch.float32 of size ]
        (3): Parameter containing: [torch.float32 of size ]
        (4): Parameter containing: [torch.float32 of size ]
    )
    (stepsize): ParameterList(
        (0): Parameter containing: [torch.float32 of size ]
        (1): Parameter containing: [torch.float32 of size ]
        (2): Parameter containing: [torch.float32 of size ]
        (3): Parameter containing: [torch.float32 of size ]
        (4): Parameter containing: [torch.float32 of size ]
    )
  )
  (prior): ModuleList(
    (0): Prior()
  )
  (data_fidelity): ModuleList(
    (0): L2()
  )
)
</pre></div>
</div>
</section>
<section id="test-the-network">
<h2>Test the network.<a class="headerlink" href="#test-the-network" title="Link to this heading"></a></h2>
<p>We now test the learned unrolled network on the test dataset. In the plotted results, the <cite>Linear</cite> column shows the
measurements back-projected in the image domain, the <cite>Recons</cite> column shows the output of our LISTA network,
and <cite>GT</cite> shows the ground truth.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">plot_images</span></a> <span class="o">=</span> <span class="kc">True</span>
<a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">method</span></a> <span class="o">=</span> <span class="s2">&quot;unfolded_pgd&quot;</span>

<span class="n">test</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="o">=</span><a href="https://pytorch.org/docs/2.0/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_dataloader</span></a><span class="p">,</span>
    <span class="n">physics</span><span class="o">=</span><span class="n">physics</span><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">device</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">plot_images</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">plot_images</span></a><span class="p">,</span>
    <span class="n">save_folder</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">RESULTS_DIR</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">method</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">verbose</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="o">=</span><a href="https://docs.python.org/3.4/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">wandb_vis</span></a><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_demo_custom_prior_unfolded_001.png" srcset="../../_images/sphx_glr_demo_custom_prior_unfolded_001.png" alt="No learning, Recons., GT" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Processing data of operator 1 out of 1

  0%|          | 0/1 [00:00&lt;?, ?it/s]
100%|██████████| 1/1 [00:03&lt;00:00,  3.13s/it]
100%|██████████| 1/1 [00:03&lt;00:00,  3.13s/it]
Test PSNR: No learning rec.: 11.28+-0.00 dB | Model: 12.16+-0.00 dB.

(12.160669326782227, 0.0, 11.280359268188477, 0.0)
</pre></div>
</div>
</section>
<section id="plotting-the-weights-of-the-network">
<h2>Plotting the weights of the network.<a class="headerlink" href="#plotting-the-weights-of-the-network" title="Link to this heading"></a></h2>
<p>We now plot the weights of the network that were learned and check that they are different from their initialization
values. Note that <code class="docutils literal notranslate"><span class="pre">g_param</span></code> corresponds to <span class="math notranslate nohighlight">\(1/\lambda\)</span> in the proximal gradient algorithm.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">dinv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">plot_parameters</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">init_params</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">params_algo</span></a><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><a href="https://docs.python.org/3.4/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">RESULTS_DIR</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">method</span></a> <span class="o">/</span> <a href="https://docs.python.org/3.4/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">operation</span></a>
<span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_demo_custom_prior_unfolded_002.png" srcset="../../_images/sphx_glr_demo_custom_prior_unfolded_002.png" alt="demo custom prior unfolded" class = "sphx-glr-single-img"/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 58.929 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-unfolded-demo-custom-prior-unfolded-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/eb9390285295101ff123875e00078549/demo_custom_prior_unfolded.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">demo_custom_prior_unfolded.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/c9bf0b726f1d22a509302786a1f657ea/demo_custom_prior_unfolded.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">demo_custom_prior_unfolded.py</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="demo_LISTA.html" class="btn btn-neutral float-left" title="Learned Iterative Soft-Thresholding Algorithm (LISTA) for compressed sensing" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="demo_vanilla_unfolded.html" class="btn btn-neutral float-right" title="Vanilla Unfolded algorithm for super-resolution" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, DeepInv.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEKFKYSGR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NSEKFKYSGR', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>