
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plug-and-play/demo_RED_GSPnP_SR.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plug-and-play_demo_RED_GSPnP_SR.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plug-and-play_demo_RED_GSPnP_SR.py:


Regularization by Denoising (RED) for Super-Resolution.
====================================================================================================

We use as plug-in denoiser the Gradient-Step Denoiser (GSPnP) which provides an explicit prior.

Hurault, S., Leclaire, A., & Papadakis, N. 
"Gradient Step Denoiser for convergent Plug-and-Play"
In International Conference on Learning Representations.

.. GENERATED FROM PYTHON SOURCE LINES 11-24

.. code-block:: Python


    import deepinv as dinv
    from pathlib import Path
    import torch
    from torch.utils.data import DataLoader
    from deepinv.optim.data_fidelity import L2
    from deepinv.optim.prior import RED
    from deepinv.optim.optimizers import optim_builder
    from deepinv.training_utils import test
    from torchvision import transforms
    from deepinv.utils.parameters import get_GSPnP_params
    from deepinv.utils.demo import load_dataset, load_degradation








.. GENERATED FROM PYTHON SOURCE LINES 25-28

Setup paths for data loading and results.
--------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 28-40

.. code-block:: Python


    BASE_DIR = Path(".")
    ORIGINAL_DATA_DIR = BASE_DIR / "datasets"
    DATA_DIR = BASE_DIR / "measurements"
    RESULTS_DIR = BASE_DIR / "results"
    DEG_DIR = BASE_DIR / "degradations"

    # Set the global random seed from pytorch to ensure
    # the reproducibility of the example.
    torch.manual_seed(0)
    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 41-45

Load base image datasets and degradation operators.
--------------------------------------------------------------------------------
In this example, we use the Set3C dataset and a motion blur kernel from
`Levin et al. (2009) <https://ieeexplore.ieee.org/abstract/document/5206815/>`_.

.. GENERATED FROM PYTHON SOURCE LINES 45-91

.. code-block:: Python


    dataset_name = "set3c"
    img_size = 256 if torch.cuda.is_available() else 32
    operation = "super-resolution"
    dataset_path = ORIGINAL_DATA_DIR / dataset_name
    val_transform = transforms.Compose(
        [transforms.CenterCrop(img_size), transforms.ToTensor()]
    )
    dataset = load_dataset(dataset_name, ORIGINAL_DATA_DIR, transform=val_transform)

    # Generate the degradation operator.
    kernel_index = 1
    kernel_torch = load_degradation(
        "kernels_12.npy", DEG_DIR / "kernels", index=kernel_index
    )
    kernel_torch = kernel_torch.unsqueeze(0).unsqueeze(
        0
    )  # add batch and channel dimensions

    # Use parallel dataloader if using a GPU to fasten training, otherwise, as all computes are on CPU, use synchronous dataloading.
    num_workers = 4 if torch.cuda.is_available() else 0

    factor = 2  # down-sampling factor
    n_channels = 3  # 3 for color images, 1 for gray-scale images
    n_images_max = 3  # Maximal number of images to restore from the input dataset
    noise_level_img = 0.03  # Gaussian Noise standart deviation for the degradation
    p = dinv.physics.Downsampling(
        img_size=(n_channels, img_size, img_size),
        factor=factor,
        filter=kernel_torch,
        device=device,
        noise_model=dinv.physics.GaussianNoise(sigma=noise_level_img),
    )
    # Generate a dataset in a HDF5 folder in "{dir}/dinv_dataset0.h5'" and load it.
    measurement_dir = DATA_DIR / dataset_name / operation
    dinv_dataset_path = dinv.datasets.generate_dataset(
        train_dataset=dataset,
        test_dataset=None,
        physics=p,
        device=device,
        save_dir=measurement_dir,
        train_datapoints=n_images_max,
        num_workers=num_workers,
    )
    dataset = dinv.datasets.HDF5Dataset(path=dinv_dataset_path, train=True)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    kernels_12.npy degradation downloaded in degradations/kernels
    Computing train measurement vectors from base dataset...
      0%|          | 0/2 [00:00<?, ?it/s]    100%|██████████| 2/2 [00:00<00:00, 105.99it/s]
    Dataset has been saved in measurements/set3c/super-resolution




.. GENERATED FROM PYTHON SOURCE LINES 92-95

Setup the PnP algorithm. This involves in particular the definition of a custom prior class.
------------------------------------------------------------------------------------------------------
We use the proximal gradient algorithm to solve the super-resolution problem with GSPnP.

.. GENERATED FROM PYTHON SOURCE LINES 95-164

.. code-block:: Python


    # Parameters of the algorithm to solve the inverse problem
    early_stop = True  # Stop algorithm when convergence criteria is reached
    crit_conv = "cost"  # Convergence is reached when the difference of cost function between consecutive iterates is
    # smaller than thres_conv
    thres_conv = 1e-5
    backtracking = True  # use backtracking to automatically adjust the stepsize
    use_bicubic_init = False  # Use bicubic interpolation to initialize the algorithm
    batch_size = 1  # batch size for evaluation is necessarily 1 for early stopping and backtracking to work.

    # load specific parameters for GSPnP
    lamb, sigma_denoiser, stepsize, max_iter = get_GSPnP_params(operation, noise_level_img)

    params_algo = {"stepsize": stepsize, "g_param": sigma_denoiser, "lambda": lamb}

    # Select the data fidelity term
    data_fidelity = L2()


    # The GSPnP prior corresponds to a RED prior with an explicit `g`.
    # We thus write a class that inherits from RED for this custom prior.
    class GSPnP(RED):
        r"""
        Gradient-Step Denoiser prior.
        """

        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.explicit_prior = True

        def g(self, x, *args, **kwargs):
            r"""
            Computes the prior :math:`g(x)`.

            :param torch.tensor x: Variable :math:`x` at which the prior is computed.
            :return: (torch.tensor) prior :math:`g(x)`.
            """
            return self.denoiser.potential(x, *args, **kwargs)


    method = "GSPnP"
    denoiser_name = "gsdrunet"
    # Specify the Denoising prior
    prior = GSPnP(
        denoiser=dinv.models.GSDRUNet(pretrained="download", train=False).to(device)
    )


    # we want to output the intermediate PGD update to finish with a denoising step.
    def custom_output(X):
        return X["est"][1]


    # instantiate the algorithm class to solve the IP problem.
    model = optim_builder(
        iteration="PGD",
        prior=prior,
        g_first=True,
        data_fidelity=data_fidelity,
        params_algo=params_algo,
        early_stop=early_stop,
        max_iter=max_iter,
        crit_conv=crit_conv,
        thres_conv=thres_conv,
        backtracking=backtracking,
        get_output=custom_output,
        verbose=True,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/deepinv/gradientstep/resolve/main/GSDRUNet.ckpt?download=true" to /home/runner/.cache/torch/hub/checkpoints/GSDRUNet.ckpt
      0%|          | 0.00/195M [00:00<?, ?B/s]      9%|▉         | 17.8M/195M [00:00<00:00, 187MB/s]     23%|██▎       | 44.1M/195M [00:00<00:00, 239MB/s]     36%|███▋      | 71.0M/195M [00:00<00:00, 259MB/s]     50%|█████     | 98.2M/195M [00:00<00:00, 269MB/s]     65%|██████▍   | 126M/195M [00:00<00:00, 278MB/s]      81%|████████  | 157M/195M [00:00<00:00, 293MB/s]     96%|█████████▌| 187M/195M [00:00<00:00, 300MB/s]    100%|██████████| 195M/195M [00:00<00:00, 281MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 165-168

Evaluate the model on the problem.
----------------------------------------------------
We evaluate the PnP algorithm on the test dataset, compute the PSNR metrics and plot reconstruction results.

.. GENERATED FROM PYTHON SOURCE LINES 168-189

.. code-block:: Python


    save_folder = RESULTS_DIR / method / operation / dataset_name
    wandb_vis = False  # plot curves and images in Weight&Bias.
    plot_metrics = True  # plot metrics. Metrics are saved in save_folder.
    plot_images = True  # plot images. Images are saved in save_folder.

    dataloader = DataLoader(
        dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False
    )
    test(
        model=model,
        test_dataloader=dataloader,
        physics=p,
        device=device,
        plot_images=plot_images,
        save_folder=RESULTS_DIR / method / operation / dataset_name,
        plot_metrics=plot_metrics,
        verbose=True,
        wandb_vis=wandb_vis,
        plot_only_first_batch=False,  # By default only the first batch is plotted.
    )



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_001.png
         :alt: Input, No learning, Recons., GT
         :srcset: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_002.png
         :alt: PSNR, F, residual
         :srcset: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_003.png
         :alt: Input, No learning, Recons., GT
         :srcset: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_003.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_004.png
         :alt: PSNR, F, residual
         :srcset: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_004.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_005.png
         :alt: Input, No learning, Recons., GT
         :srcset: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_005.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_006.png
         :alt: PSNR, F, residual
         :srcset: /auto_examples/plug-and-play/images/sphx_glr_demo_RED_GSPnP_SR_006.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Processing data of operator 1 out of 1
      0%|          | 0/3 [00:00<?, ?it/s]Iteration 26, current converge crit. = 9.16E-06, objective = 1.00E-05 
     33%|███▎      | 1/3 [00:03<00:06,  3.29s/it]Iteration 54, current converge crit. = 9.84E-06, objective = 1.00E-05 
     67%|██████▋   | 2/3 [00:08<00:04,  4.38s/it]Iteration 22, current converge crit. = 8.26E-06, objective = 1.00E-05 
    100%|██████████| 3/3 [00:11<00:00,  3.83s/it]    100%|██████████| 3/3 [00:11<00:00,  3.87s/it]
    Test PSNR: No learning rec.: 6.06+-1.18 dB | Model: 29.26+-1.57 dB. 

    (29.255968729654949, 1.5749010239002867, 6.0601496696472168, 1.1836217893424801)




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 13.922 seconds)


.. _sphx_glr_download_auto_examples_plug-and-play_demo_RED_GSPnP_SR.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_RED_GSPnP_SR.ipynb <demo_RED_GSPnP_SR.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_RED_GSPnP_SR.py <demo_RED_GSPnP_SR.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
